// TODO all source code with tabs

TODO about the author

Content
-------
TODO

The book has not been proofreaded! There are probably many typos and many language mistakes (my apologies!).

THIS IS WORK IN PROGRESS!
About TODO - it means some part/sentence/paragraph is not finished

TODO What you should know.

TODO not "bad" but rather "imperfect"

TODO about the idea of the book - only "bad" tests that I have seen myself

To really benefit from reading this book you should:

* have some experience in writing tests, especially unit tests,
* know a testing framework; preferably TestNG, but any other will also be fine (but you have to scan TestNG documentation to understand code samples),
* be interested in improving your tests-writing skills,
* understand the value of clean test code.

The source I recommend is my book{empty}pass:[]footnote:[See http://practicalunittesting.com] (well, of course!) but to be honest you can learn most of it by doing a research on your own (web has it all, but you have to find it first and it takes time!).

TODO about +setUp()+ what I mean by this

TODO Differences with THE book. Here more strict view, no discussion of possible options, no explanations. Zero or one. Stop or go. White or black. No shades of grey.

== Why Bother?
This book is not meant to explain all the reasons of writing tests but there are few things we should know. In short, there are three main reasons for writing tests{empty}pass:[]footnote:[Please forgive the simplifications - I want to make it short!]:

* If we have a complete set of tests, and they all pass, then we know that our application works.
* Making changes is much easier if we have tests. They will inform us if we break some functionality.
* Tests are probably the only documentation we have which stays up-to-date during the whole life of ours software.

You should recall these reasons for writing tests when looking at the examples of *bad* tests presented in this book. Ask questions like '"does it test anything?"', '"is it maintainable"', '"is it easy to understand?"' etc.

TODO Whatever you do, do it good. If it is worth doing, it is worth doing well. Numerous accounts of people who introduced tests to their development process... and failed!

== Introduction
I would like to start our journey through various tests by going few years back. The tests discussed in this section were written in years 2004-2006. In fact, they are full of atrocities of the worst kind. Any single of them could kill a code-clean acolyte. ;) I've received these tests Bartosz{empty}pass:[]footnote:[You can follow Bartosz at https://twitter.com/#!/bocytko] who mentions some of their properties:

* The tests were written in 2004-2006.
* They were never a part of any serious test harness (i.e. no regular execution on CI server).
* Some tests do not even compile.
* In some tests you can read a comment that "WARNING: test requires the divide param to be set to 20" but the code is so ugly, that there is no way to inject this value.
* Some test data are available in form of serialized objects (+*.ser+) that can not be currently deserialized, because the classes have changed.
* The project is now in maintenance.

[NOTE]
.Cast the first stone...
=====================================================================
The reason we look at these tests is not to have a laugh at developers who have written them. I do not doubt they did the best they could. I wonder myself wheter in 2004 I was able to write better tests, or even whether I was able to write any tests at all... There are two reasons I discuss these ancient tests. Firstly, let us see how much more educated and experienced we (as a community of developers) are in the area of tests. Secondly, there is much to learn even from such imperfect tests.
=====================================================================

Ok, so now let's dive into the dark ages of testing and see what we can learn from it.

=== It is a Full Time Job
TODO thanks Bartosz

Let's face it - writing tests makes sense only if you (and your team) take care about them every day. In this section I present two examples of what happens when it is no so.

First is a short snippet of +SystemAdminSmokeTest+ class. *Smoke test*, mind you, which means this is an important test that intends to give you quick feedback about the health of the system. This test, at the time I joined this project, looked as follows:

----
class SystemAdminSmokeTest extends GroovyTestCase {

void testSmoke() {
// do not remove below code
// def ds = new org.h2.jdbcx.JdbcDataSource(
//     URL: 'jdbc:h2:mem:test;DB_CLOSE_DELAY=-1;MODE=Oracle',
//     user: 'sa', password: '')
//
//     def jpaProperties = new Properties()
//     jpaProperties.setProperty(
//			'hibernate.cache.use_second_level_cache', 'false')
//     jpaProperties.setProperty(
//			'hibernate.cache.use_query_cache', 'false')
//
//     def emf = new LocalContainerEntityManagerFactoryBean(
//        dataSource: ds, persistenceUnitName: 'my-domain',
//        jpaVendorAdapter: new HibernateJpaVendorAdapter(
//            database: Database.H2,  showSql: true,
//            generateDdl: true), jpaProperties: jpaProperties)

   ... 
}
----
Well, it is not gonna inform anyone about the state of the system... I guess there was a time when this test used to work. But then some changes came and it was commented out (I bet it was commented out only '"for a very short time"'....) and it was never brought to life again. A pity, yes. And a rather discouraging sign to anyone joining the team{empty}pass:[]footnote:[Which was misleading BTW, because the project and the team were doing pretty well!].

Another example is even more depressing. In one of the modules of some project I found this test in +src/test/java+ directory:

----
@Test
public class ExampleTest {

	public void testExample() {
		assertTrue(true);
	}
}
----
I think you've already guessed the end of this story. Yes, that was the only test there...

And what can we learn from these two failures? Few things:

* Do not live with '"broken windows"'{empty}pass:[]footnote:[See http://c2.com/cgi/wiki?FixBrokenWindows]; fix things immediately!
* Writing and maintaining tests is an effort which has to be taken by the whole team (and this effort must be also supported, or at least not hindered, by all stakeholders).
* Good intentions are not enough. You also need knowledge, time and determination to meet the goal of well-tested software.

=== Autogeneration
Unit tests are simple, right? All they do is they set some object, call its methods, and verify results, right? So, why don't we make computers write them? Hip-hip hurray, we will save a plenty of time, and have 100% code coverage! Let's do it!

...well, it simply does not work, you know. If you think about *why* you really write tests, you will quickly understand that this is a bad idea. It does not help to discover bugs, it does not help you come with better design, it promotes test-last coding and goes against '"test behaviour not methods"' rule. Which really mean, that you should not do it. Howgh!

Below is an attempt to autogenerate some test code (using JUnitDoclet tool{empty}pass:[]footnote:[Nope, not link to project website this time, because I do not think you should use it. :)]). As you can see it successfully generated tests for getters/setters, which is, shortly speaking, a waste of time.

----
public void testSetGetTimestamp() throws Exception {
    // JUnitDoclet begin method setTimestamp getTimestamp
    java.util.Calendar[] tests = {new GregorianCalendar(), null};

    for (int i = 0; i < tests.length; i++) {
    	adapter.setTimestamp(tests[i]);
    	assertEquals(tests[i], adapter.getTimestamp());
    }
    // JUnitDoclet end method setTimestamp getTimestamp
}

public void testSetGetParam() throws Exception {
    // JUnitDoclet begin method setParam getParam
    String[] tests = {"a", "aaa", "---", "23121313", "", null};

    for (int i = 0; i < tests.length; i++) {
    	adapter.setParam(tests[i]);
    	assertEquals(tests[i], adapter.getParam());
    }
    // JUnitDoclet end method setParam getParam
}
----
So now repeat after me: '"I will not autogenerate nor the test code, neither its skeleton. I will not autogenerate nor the test code, neither its skeleton. I will not autogenerate nor the test code, neither its skeleton. I will not autogenerate nor the test code, neither its skeleton..."' (pretty useful mantra if you can't fall asleep, should help after 1000 repetitions).

=== No assertions, manual verification
TODO

=== Conclusions
TODO 

* it is an everyday effort,
** (vs. follow the leader, and commented out smoke test)
* do not generate, write them!,
* master your tools (or at least learn the basics),
* tests should inform about the reason they failed.

////
== Flickering Tests
Flickering tests are a serious disease which can be very hard to cure. Once you caught it you can spend days trying to figure out what is going on. One time your tests are [green]#green#, next time they are [red]#red#, then everything is back to normal, but after some time the situation repeats - without any code changes which could possibly cause such result!

This can really turn your hair grey! Usually, such indeterministic behaviour is related to some external systems your tests rely on. Perhaps some 3rd party webservice goes bananas from time to time and responds with nonsensical data. Or maybe there is some subtle bug in the time-related logic of your system which makes your test fail occasionally. 

But sometimes it is our lack of thoughtfullness which can bring that doom on ourselves. At least its mild form - a test which suddenly turns from [green]#green# to [red]#red# without any significant code change (and probably stays like this, which makes it much simpler to debug than the real flickering test).
////

== Do Not Modify Global State
A rule of thumb is to keep tests independent from each other. If we forget about this we can bring serious problems on our heads.

Let us have a look at the following example. The test presented below verifies whether log4j{empty}pass:[]footnote:[http://logging.apache.org/log4j/] configuration code works fine. If some system property (+logConfig+) is available, it should load file specified by this property. If the property is not set it should load some default values.

----
LoggingPropertyConfigurator configurator 
	= mock(LoggingPropertyConfigurator.class);
BaseServletContextListener baseServletContextListener 
	= new BaseServletContextListener(configurator);

@Test
public void shouldLoadDefaultProperties() {
	baseServletContextListener.contextInitialized(null);
	verify(configurator).configure(any(Properties.class));
}

@Test(expected = LoggingInitialisationException.class)
public void shouldThrowLoggingException() {
	System.setProperty("logConfig", "nonExistingFile");
	baseServletContextListener.contextInitialized(null);
}
----
This test used to be [green]#green# for months. Then, suddenly, it turned [red]#red#. Why?! For no apparent reason, the log4j config was not something we changed often. In fact, we haven't touched it for a long time... The reason was, that this test relied on the order of execution. As long as +shouldLoadDefaultProperties+ was executed before +shouldThrowLoggingException+ everything was fine. But once this order was changed, things started to go wrong. In particular, the +logConfig+ system property was available when +shouldLoadDefaultProperties+ test was executed which altered the behaviour of SUT and made this test fail.

And why did the order of execution changed? Well, it does not really matter. In general test frameworks do not guarantee the order of execution (unless you explicitely ask for it) so you should not rely on this.

TIP: Be extra cautious when modifying 'global state' (system properties, database etc.) in your tests. This can influence other tests.

Now, how to fix it. Basically there are two solutions.

First, you can impose strict order of execution of these two test methods (TestNG will allow you to do this, JUnit won't).

[role="pseudocode"]
----
@Test
public void shouldLoadDefaultProperties() { ... }

@Test(expected = LoggingInitialisationException.class,
	dependesOnMethod = "shouldLoadDefaultProperties")
public void shouldThrowLoggingException() { ... }
----

This works as long as there are no more tests which outcome also depend on the value of +logConfig+ system property. If such tests are added you need to remember to also specify their relation (their depedency) to these existing tests.

Another option is to clean +logConfig+ system property variable before +shouldLoadDefaultProperties+ is executed (if you have more test here then maybe putting this into some +setUp()+ method would be a good idea),

[role="pseudocode"]
----
@BeforeMethod
public void cleanSystemProperties() {
	System.setProperty("logConfig", null);
}

// the rest of the code remains unchanged
----

TIP: Keep your tests independent from each other. Or at least make the dependency explicit!

== Mock'em All!
[quote, Abraham Maslow]
_______________________
To a man with a hammer everything looks like a nail.
_______________________
This is something I observe frequently among developers who has only recently discovered the pleasures of mocking. :) They tend to overuse all kind of test doubles even when it is not really the best option. Let us see an example.

The code below intends to verify whether some data is added to +modelAndView+ object{empty}pass:[]footnote:[This is +ModelAndView+ from Spring MVC framework.]. Yes, you heard it right: it verifies whether something is *added*. Even the method name states this explicitly.

----
@Test
public void shouldAddTimeZoneToModelAndView() {
	//given
	UserFacade userFacade = mock(UserFacade.class);
	ModelAndView modelAndView = mock(ModelAndView.class);
	given(userFacade.getTimezone()).willReturn("timezone X");

	//when
	new UserDataInterceptor(userFacade)
		.postHandle(null, null, null, modelAndView);

	//then
	verify(modelAndView).addObject("timezone", "timezone X"); 
}
----
This is of course wrong. The thing we really care about is whether +modelAndView+ contains certain data, not whether some methods of +modelAndView+ were called!

Below you can see an improved version of this test. It treates SUT more like a black box and only cares about its output.

[role="pseudocode"]
----
@Test
public void shouldAddTimeZoneToModelAndView() {
	//given
	UserFacade userFacade = mock(UserFacade.class);
	ModelAndView modelAndView = new ModelAndView();
	given(userFacade.getTimezone()).willReturn("timezone X");

	//when
	new UserDataInterceptor(userFacade)
		.postHandle(null, null, null, modelAndView);

	//then
	assertThat(modelAndView).contains("timezone", "timezone X");
}
----
As you can see in the second version we use real object, not a test double. And this is fine, because +ModelAndView+ is not a service, but a value object, which should not be mocked. Howgh!

TIP: Excited that you can mock everything, huh? Slow down and make sure that you really need to verify interactions. Chances are you don't.

[[sec_time_means_troubles]]
== Time Means Troubles (Always!)
TIP: As a rule *never* use +System.currentTimeMillis()+ or +new Date()+ in your production code. Add an additional layer of abstraction - e.g. a +DateTimeProvider+ interface will let you test your time-dependent methods with ease.

Let us see what happens when you do not follow this advice.

An obvious example would look like this:

[role="pseudocode"]
----
time = System.currentTimeMillis();

if (time.isAfter(5, PM)) {
	... do some afternoon activity
}
else {
	... do somethig else
}
----
Well, this one is obvious - you can't test all paths util you control the value of time variable.

But let us see a real, slightly more subtle example. Let us take a look at this fragment of production code (the +Util+ class):

----
public String getUrl(User user, String timestamp) {
	String name=user.getFullName();

	String url=baseUrl
		+"name="+URLEncoder.encode(name, "UTF-8")
		+"&timestamp="+timestamp;
	return url;
}

public String getUrl(User user) {
	Date date=new Date();
	Long time=(date.getTime()/1000); //convert ms to seconds
	String timestamp=time.toString();
	return getZendeskUrl(user, timestamp);
}
----

Testing of such methods should be straightforward - they return some +String+ which we could analyze and verify its correctness. Alas, because the +new Date()+ was used, the programmer responsible for this code was not able to verify the resulting URL. Instead, he came up with the following test:

----
@Test
public void shouldUseTimestampMethod() {
        //given
	Util util = new Util();
        Util spyUtil = spy(util);

        //when
        spyUtil.getUrl(user);

        //then
        verify(spyUtil).getUrl(eq(user), anyString());
}
----
Oh my, this is bad for few reasons. This test:

* tests implementation instead of behaviour,
* uses partial mocking (+spy+ method on real object) which is rarely required (a [red]#red# lamp should start blinking in your head when you see it),
* verifies interactions instead of returned values.

And all of this because the production code does not handle properly time!

TIP: See <<sec_fix_the_code_first>> for some more examples of writing tests instead of fixing the code first!

After we redesign the production code by replacing call to +new Date()+ with a call to some collaborator, our test starts looking pretty nice:

----
@Test
public void shouldAddTimestampToGeneratedUrl() {
	//given
	Util util = new ....
	TimeProvider timeProvider = mock(TimeProvider.class);
	when(timeProvider.getTime()).thenReturn("12345");
	util.set(timeProvider);

	//when
	String url = util.getUrl(user);

	//then
	assertThat(url).contains("timestamp=12345");
}
----

TIP: If tested method return some values then try to use this values to verify whether the method works fine. Use mocks/spies only if it is really required{empty}pass:[]footnote:[Please note that the +shouldAddTimestampToGeneratedUrl+ method does not use mocks but a stub only!].

[[sec_srp]]
== SRP for Tests
We are all familiar with Single Responsibility Principle{empty}pass:[]footnote:[SRP, see http://en.wikipedia.org/wiki/Single_responsibility_principle], which basically says that every class should take care of one thing. I think it is very valuable to think about tests in terms of SRP. In case of tests, each test method should conform to the following rule: '"Each test method should verify one scenario"'.

Why? Because:

* such test methods are pretty simple to understand,
* if they fail you know *exactly* which functionality of your software does not work.

NOTE: Writing tests which fullfil the SRP principle is very simple for unit tests, but not always applicable for other kind of tests.

Still, I observe it being breached frequently. Let us have a look at an example. It comes from a simple utility class, which was responsible for making sure that the phone prefix entered by users are valid.

----
@DataProvider
public Object[][] data() {
	return new Object[][] { {"48", true}, {"+48", true}, 
		{"++48", true}, {"+48503", true}, {"+4", false},
		{"++4", false}, {"", false},
		{null, false}, {"  ", false}, };
}

@Test(dataProvider = "data")
public void testQueryVerification(String query, boolean expected) {
	assertEquals(expected, FieldVerifier.isValidQuery(query));
}

----
At the first sight, it may seem like the test is really focused on one thing (on the verification of query validity), but if you look closer you will see some alarming signals:

* its method name is quite generic, and it would be hard to use a '"should"' prefix (see <<sec_should>>),
** also the name of data provider - +data+ - smells really bad,
* it has some kind of logic: assertions depends on passed +expected+ boolean flag,
* a "generic" assertion - +assertEquals+ - is used to verify the outcome.

//(see <<sec_no_logic>>).

To discover if your test fulfills SPR ask the following question: '"if it fails will I be able to discover what fuctionality of my software is broken just by reading the name of the failed test method?"'.

Here is the same tests (meaning, test which verifies exactly the same scenarios) but divided into two parts:

----
@DataProvider
public Object[][] validQueries() {
	return new Object[][] { {"48"}, {"48123"}, 
		{"+48"}, {"++48"}, {"+48503"}};
}

@Test(dataProvider = "validQueries")
public void shouldRecognizeValidQueries(String validQuery) {
	assertTrue(FieldVerifier.isValidQuery(validQuery));
}

@DataProvider
public Object[][] invalidQueries() {
	return new Object[][] { 
		{"+4"}, {"++4"}, 
		{""}, {null}, {"  "} };
}

@Test(dataProvider = "invalidQueries")
public void shouldRejectInvalidQueries(String invalidQuery) {
	assertFalse(FieldVerifier.isValidQuery(invalidQuery));
}
----
This version is longer, but more readable, easier to understand (no boolean flag), and it follows the SRP rule. What I really like here are the names - all of them describe very well the purpose of elements. We have a data provider which provides +validQueries+, and a test method which takes +validQuery+ as a parameter.

TIP: Watch the method names. Are they intention-revealing?

TIP: No logic in tests! Even the simplest one is evil!

// TODO would be nice to have some other examples of this - not everyone uses data providers / parameterized tests

And now, a counter example. Yes, after I have tried to convince you that it is good to split tests into smaller ones (each testing a unique test case), I will show an example of the opposite approach.

Take a look at the test method below:

----
TODO CW CampaignBid/shouldRecognizeDomain
----

It verifies two things, namely:

* whether +CampaignBid+ is capable of recognizing the same domain (which it was constructed with - I haven't presented the constructor, but it takes +Domain+ as one of parameters),
* whether +CampaignBid+ is capable of recognizing domains which are different from the one it was constructed with.

Should we split it in two tests then? My answer is no.

In contrast to the previous example, there are not many cases to test here, so the test method is very concise and simple to understand. In other words, the size of this method (taking into account the number of test cases it verifies, not only number of lines it has) has not exceeded my private safety limit. And thus, I do not feel like having two testing methods instead.

But if you feel differently, then here comes the two-methods version:

----
TODO
----

TIP: Rules are to be broken. ;)

////
[[sec_no_logic]]
== Logic in Tests
TODO need some good examples of this

avoid by using some features of your testing framework - annotations data provider instead of for loops (TODO ref) and concurrent with annotations

TODO refer to SRP - boolean is also kind of logic
////

== Use Smart Values
Try to minimize the risk of having your tests pass by accident. And always work to improve the readability.

Let us consider the following factory method:

----
public PayoutCalculator create() {
	BigDecimal minMargin = settings.getMinMargin();
	BigDecimal maxMargin = settings.getMaxMargin();
	BigDecimal premiumShare = settings.getPremiumShare();
	return new PayoutCalculator(minMargin, maxMargin, premiumShare);
}
----
+settings+ is a collaborator, and as such should be stubbed in test.

This test does exactly this:

----
public class PayoutCalculatorFactoryTest {
	PayoutSettingsService settings = mock(PayoutSettingsService.class);

	@Test
	public void shouldCreatePayoutCalculator() {
		//given
		given(settings.getMinMargin()).willReturn(new BigDecimal(20));
		given(settings.getMaxMargin()).willReturn(new BigDecimal(50));
		given(settings.getPremiumShare()).willReturn(new BigDecimal(50));

		//when
		PayoutCalculator calculator = new PayoutCalculatorFactory(settings).create();

		//then
		assertThat(calculator)
			.isEqualTo(new PayoutCalculator(new BigDecimal(20), new BigDecimal(50), new BigDecimal(50)));
	}
}
----
Even if the values used in test (+minMargin+ = 20, +maxMargin+ = 50, +premiumShare+ = 50) makes business sense, they should not be used in test. Why? Because there is always a chance, that the tested method is flawed and values are improperly assigned (this can happen if someone created it with *copy&paste* approach). To minimize the risk use different values. The following code shows this (also there is some refactoring done so the values are extracted as +static final+ fields):

----
public class PayoutCalculatorFactoryTest {
	PayoutSettingsService settings = mock(PayoutSettingsService.class);
	
	private static final BigDecimal MIN_MARGIN = new BigDecimal(20);
	private static final BigDecimal MAX_MARGIN = new BigDecimal(30);
	private static final BigDecimal PREMIUM_SHARE = new BigDecimal(40);

	@Test
	public void shouldCreatePayoutCalculator() {
		//given
		given(settings.getMinMargin()).willReturn(MIN_MARGIN);
		given(settings.getMaxMargin()).willReturn(MAX_MARGIN);
		given(settings.getPremiumShare()).willReturn(PREMIUM_SHARE);

		//when
		PayoutCalculator calculator = new PayoutCalculatorFactory(settings).create();

		//then
		assertThat(calculator)
			.isEqualTo(new PayoutCalculator(MIN_MARGIN, MAX_MARGIN, PREMIUM_SHARE);
	}
}
----

TIP: Avoid using same numbers/strings for different variables/properties in your tests method! Often power of 2 are quite convenient (they do not sum up to each other easily).

== Database Assumptions
Take a look at this test:

----
@Test
public void shouldAddAUser() {
	User user = new User();
	userService.save(user);
	assertEquals(dao.getNbOfUsers(), 1);
}
----

Well, the test looks like an integration test (seems like +userService+ and +dao+ talk with real database), which adds a new user to the database.

What is bothering me here is that:

1. it does not really verify if the user was added,
2. it makes some assumptions regarding the state of the database before it is executed,

Regarding the first point, this should be probably done by verifying that the user in the database is equal to the +user+ object. This can be straigforward provided that +userService+ or +dao+ provides appropriate method(s) to fetch the user, or can require much more work (e.g. writing custom JDBC queries directly to database and parsing results in your test code... yuck!).

As for the second issue the solution is quite simple - replace absolute values with relative ones:

----
@Test
public void shouldAddAUser() {
	int nb = dao.getNbOfUsers();
	User user = new User();
	userService.save(user);
	assertEquals(dao.getNbOfUsers(), nb + 1);
}
----
Now the content of the test method reflects its name (+shouldAddUser+). Good.

And BTW. I believe that in many cases such check is good enough to make sure that the user was really added to the database (without really checking whether it is exactly the same user - which should be the case provided that your services and daos are performing simple CRUD operations).

It happened that the assumption on database state (i.e. the assumption that there are no users at all) caused some additional work for my team some time ago. At some point it occured that we need to add a 'fake' user to the system (the reason was to handle some extra-cases, do not show them on reports etc.). After creating a database patch we observerd (with amazement) that many tests started to fail. Why? Because they assumed that the database has no users at all.

TIP: Do not make assumptions about the database content. Use relative rather than absolute values.

TIP: Make sure the test does exactly what its (method) name promises.

== Happy Path
The issue of writing '"happy path"' tests is so common, that it is probably the most popular antipattern of all.

But what is a '"happy path"' testing anyway? For our purpose, it is enough to say that '"happy paths"' tests cover the simplest, even obvious, scenarios. It is like testing that our calculator can add +2+ and +2+, and that if you add user +John Doe+ to the database then you can found it there.

Let me stress one thing though. Such tests are not evil. There is nothing wrong with having them. On the contrary *there are essential*. Why? Because the scenarios they cover are the most important for you application. If your application does not handle such simple cases than it is useless. So the problem is not with writing such tests, but with the fact that they are often the only tests there are. This of course leads to the problems as soon as the real data comes in - suddenly it occurs that your calculator can't handle negative values, and that your database is not prepared to handle a surname longer than 20 characters or so. And your clients will notice it really soon.

TODO what example here?

== Naming is the King
This is interesting because we are usually very good at giving good names to methods and variables in production code. However when it comes to tests we drop the good habits and perform a bad job. I suspect this is because in tests it is quite normal to have few objects of them same type which results in simple naming schemas like +productA+, +productB+, +productC+ etc. Sometimes it is good enough, but sometimes it could be well improved.

The first example presents a simple case of a test related to permission-checking module. The next listing shows a small fragment of this test - a data provider which feeds test methods with data.

----
@DataProvider
public static Object[][] userPermissions() {
    return new Object[][]{
        {"user_1", READ},
        {"user_2", READ},
        {"user_2", WRITE},
        {"user_3", READ},
        {"user_3", WRITE},
        {"user_3", DELETE}
    };
}
----

As you can see it connects three users (+user_1+, +user_2+, +user_3+) with some permissions (+READ+, +WRITE+, +DELETE+). Fine, but why +user_1+ can only +READ+ while +user_3+ can also +WRITE+ and +DELETE+? This is not obvious and if some test fails you will learn someting like: '"+user_3+ was expected to have +DELETE+ permission"'. Then you start scratching your head wondering why actually +user_3+ should have such permission. Of course the answer is nowhere to be found. It was obvious few months ago when this test was created but now? Who knows what the heck is +user_3+?

And the cure? See below.

----
@DataProvider
public static Object[][] userPermissions() {
    return new Object[][]{
        {"guest", READ},
        {"logged", READ},
        {"logged", WRITE},
        {"admin", READ},
        {"admin", WRITE},
        {"admin", DELETE}
    };
}
----

A guest can only read, logged users can also write, and admin has all permissions. Now the error message - e.g. '"+admin+ was expected to have +DELETE+ permission"' makes sense.

Now let us consider another example. This is a (tiny) part of a complex integration test which creates a bunch of objects (mainly of the +Domain+ class). It uses a lot of helper methods which are responsible for creation of objects and also for saving them into the database.

----
Domain domain1 = daoTestHelper.someUtilityMethodWhichCreatesDomain(...)
daoTestHelper.anotherUtilityMethodWhichSetsSomeProperties(domain1, "PL", 1);
daoTestHelper.anotherUtilityMethodWhichSetsSomeProperties(domain1, "US", 1);
Domain domain2 = daoTestHelper.someUtilityMethodWhichCreatesDomain(...)
daoTestHelper.anotherUtilityMethodWhichSetsSomeProperties(domain2, "PL", 4);
daoTestHelper.anotherUtilityMethodWhichSetsSomeProperties(domain2, "US", 8);

// and so on till domain5 or so
----

What I hate about this are the names of domain objects suffixed with numbers (+domain1+, +domain2+ etc.). They bring no information about the state (role, properties) of the objects and make assertions quite mysterious:

----
TODO assertion message here
----

Why do we expect TODO +domain4+ to have exactly TODO? To understand this we need to go back to where it was created and read it line by line. We can do a little better if we use a more descriptive name for our domains. This is shown below.

----
TODO
----

Now the assertion looks better. We expect TODO to have TODO, which seems reasonable.

BTW. While refactoring this test, I have found an interesting thing. Look at the original code once again. Can you see it?

----
TODO
----

Well, maybe you spotted it, but I hadn't when I worked with the code (ok, you knew there is something wrong there, and I hadn't). Only when I started renaming thing I noticed that +domain3+ is used where +domain4+ should had been used. It hasn't influenced the outcome of the test (because this line is responsible for adding data which should not be included in the final result), but still it illustrates very well what happens if all variables names differ only so slightly. It is very simple to mix things up.

TODO img

.Conclusion
It is the same like with classes. At first you begin with useless names like +ClientDAOImpl+ but then you learn that you can have much more intention-revealing names. +HibernateClientDAO+, +InMemoryClientDAO+, +HighPerformanceClientDAO+ or whatever describes this particular implementation. There is always something to say about your class. I believe the same applies to the variables used in tests. I often start with +campaignA+ and +campaignB+ but then it occuress to me that these should be really +campaign+ and +campaignWithSameAdvertiser+ (while in other test method I have +campaign+ and +campaignWithDifferentAdvertiser+). Try it, it makes your test code so much more readable!

=== What do True and False Stand For
If we expect our tests to act as a documentation then we need to put some effort into their readability. Consider the following example:

----
server = new MockServer(responseMap, true,
		new URL(SERVER_ROOT).getPort(), false);
----
This single line of code is responsible for creation of some +MockServer+. It is later used in test code.

Nice, but what the heck does +true+ and +false+ mean here? What kind of server are we creating?

Well, I do not expect you to have JavaDocs for +MockServer+ (which sounds like a utility class create especially for testing purposes), which means you need to browse the source code to find out. This is not a major problem (but may be - depending on the complexity of +MockServer+ class), however this is a nuissance. And it means that this test does not play the role of documentation very well. In order to understand the test case we need to browse another documents (i.e. source code). This is not a tragedy, but this is not good either.

And what can we do about this? There are at least two options.

First, we could create some static variables, with intention-revealing names, like this:

----
private static final boolean RESPONSE_IS_A_FILE = true;
private static final boolean NO_SSL = false;

server = new MockServer(responseMap, RESPONSE_IS_A_FILE,
		new URL(SERVER_ROOT).getPort(), NO_SSL);

----
Now there is no doubt what kind of server is created. It does not use SSL and responds with a file. Better, isn't it? And we haven't had to work very hard to achieve this effect.

Second approach requires some more work. Yeah, you guessed it already - we could use a test data builder idea and express very clearly what kind of server is required. For example like this:
----
server = new MockServerBuilder()
		.withResponse(responseMap)
		.withResponseType(FILE)
		.withUrl(SERVER_ROOT)
		.withoutSsl().create();
----
Is this approach better than the previous one? Definitely it requires more work. Probably the more complex, and more frequently created, the class in question is, the more benefit test data builders would bring us.

TODO ref to test data builders chapter

[[sec_should]]
=== Should is Better than Test
* the names of test methods
TODO in relation to "test behaviour not methods"

TODO testOperation example
TODO testQuery example - breaks SRP <<sec_srp>>

Take a look at this example. As the method name says it '"tests query"'. 

== Say No to Complex Assertions
TODO example from domain1 where for loop was used to get the data to be asserted

TODO example SSHAssert

TODO refer to test data builders - this is the other side of the same coin

TIP: Let your tests speak with domain language, not in implementation terms.

== Avoid Assertions using Private Methods
So you have a test scenario. It is a complex integration test which covers some important functionality. At the end of it you write some assertions to make sure that the data in the database are in expected state. It can look like this:

----
TODO

test with assertState but inline, and with less assertions.
----

So far so good. Now you write other tests. You soon discover that the assertions are very similar to the ones you have already written. '"Reuse is good"' you think and you do the most obvious thing - you create a +private+ method and call it from both tests (and later from more tests).

And all is good, at least for some time. You write more tests still reusing this one assertion method. But soon you encounter problems. The assertions in the method are not exactly what you need in some particular test cases. They are very close to what you want, but not exactly. '"Reuse is good"' you say and make your private method more generic so it can handle more test cases. The result is presented below:

----
TODO normal assertState() method
----

Oh my, this has come too far... Now we have a monster-method which verifies every possible scenario! It takes TODO almost 10 parameters and has some logic. This is unmaintainable. You can't read your tests now and understand what scenario is really tested (without doing some serious investigations).

And what can be done about it.

* assertions
* setup

TODO rule of a thumb: whenever your assertions are growing beyond your safety limit (2 lines? 3 lines? 5 lines? I do not know, it is *yours safety limit* not mine) then introduce custom assertions instead. In fact, it seems reasonable to come with custom assertions for the main objects from your domain (because you will probably have many tests which involve them - both on unit and integration level).

And how to come with good custom assertions method? My trick is simply to write it so I am happy while reading this. So, without actully having any custom assertion implemented I write a line like this in my test code:

----
assertThat(client).isVip().and().hasDiscount(0.2)
----

And then I implement it. Of course sometimes it happens that I need to deviate from the original plan and that the resulting fluent interface differs in details, but usually I'm able to come quite close to what I imagined.

=== Cost of Custom Assertions
There is a question which could be asked by an inquisitive reader. Custom assertions contain some code, even some logic. How can I be sure that there is no mistake there?

Ok, I admit. I do not test my custom assertions. This comes from the fact that the logic of custom assertions is very limited (if any at all).

TODO question how do you test your custom assertions? I don't. 1) It is moving lines from test (which wouldn't have been tested anyway) 2) they are dead simple

== Excessive SetUp
TODO merge with previous one?

builders

TODO example from DaoTestHelper - construction of objects with few BigDecimal parameters - show how to replace with constants and builders Problems: hard to understand.

== Things to Remember

* Single Responsibility Principle for tests
* Names are important!
* Test behaviour, not methods!
* Ask yourself "what is the purpose of this test?", "what is really important?"
* Think about readability (just say it)
* Test-last does not work
* Private methods for assertions do not work
* Tests work only if you treat them as first-class citizens

== Know Your Tool
TODO

[[sec_thread_sleep]]
Thread.sleep()
--------------
TODO any example of such things?

* got selenium one - mention it can leverage what frameworks provide
* need something else to introduce awaitility

Test Which Knows Too Much
-------------------------
Why tests are brittle? Because we put too many details into them. See the following example (this is a slightly shorthened test which from some mailing list discussion).
----
public void createSurvey() throws InterruptedException {		
	//CREATE SURVEY
	WebElement allproject = driver.findElement(By.xpath("//*[@id='projectnav']/ul/li[2]/a"));
	allproject.click();
	
	Thread.sleep(5000);
	
	WebElement myfolder = driver.findElement(By.linkText("John Doe"));
	myfolder.click();
		
	Thread.sleep(5000);
		
	WebElement myProject = driver.findElement(By.linkText("My project"));
	myProject.click();
		
	Thread.sleep(5000);
		
	WebElement createsurveylink = driver.findElement(By.xpath("//*[@id='bcontrol']/body/form[1]/table[2]/tbody/tr/td[2]/a[1]/img"));
	createsurveylink.click();
				
	Thread.sleep(5000);
		
	WebElement surveyname = driver.findElement(By.xpath("//*[@id='bcontrol']/body/form/table[4]/tbody/tr[2]/td[3]/input"));
	surveyname.sendKeys("Test Survey created on " + new Date());
		
	WebElement surveynameconfirm = driver.findElement(By.xpath("//*[@id='bcontrol']/body/form/table[1]/tbody/tr[2]/td[3]/a[2]/img"));
	surveynameconfirm.click();
		
	Thread.sleep(5000);
}
----
Before we get to the main point, let us discuss the idea of having +Thread.sleep()+ calls in your tests once again. We already did this in <<sec_thread_sleep>> but here situation is slightly different. The main reason of making the test so sloooooooow is because we are not sure when the browser will finish rendering the page so we can proceed the next click. True, we do not know that, so a defensive strategy is to set up some high values (5 seconds in this case) to stay on the safe side. It works, but makes your tests execution time horrible!

So, what can we do about it?  We can't make browser speed up, but we can wait actively, that is wait and repeatedly verify whether we can move do the next click. TODO about internal selenium mechanisms and about awaitility

TODO about Page objects

So, putting these two together, the resulting test could look like this (it is hard to me to guess what was the business requirement of the test presented above, but I guess it was something like this):

----
public void shouldCreateSurvey() {
	Date date = new Date();

	ProjectsPage projectsPage = mainDashboard.goToProjectsPage();

	projectsPage.openProject("My project");

	SurverEditionPage surverEditionPage = projectsPage.createSurvey("Test Survery created on " + date);

	// there were no assertions in the original tests (which was rather weird...),
	// but I guess something like this would make sense
	String surveyName = surveyEditionPage.getEditedSurveyName();

	assertThat(surveyName).isEqualTo("Test Survey created on " + date);
}
----
What can we see here? Few things:

* most of the work is delegated to various +xyzPage+ objects which handle things like XPath access to various elements,
* no +Thread.sleep()+ - this is also handled internally by +xyzPage+ objects,
* this test would survive refactorings as long as the general flow of actions remains unchanged.

All this does not mean that the nasty low-level details have miracouleously vanished. No, as we already mentioned, they were moved to +xyzPage+ classes. For example, the +ProjectsPage+ class could look like the following:

----
TODO
----

[[sec_fix_the_code_first]]
== Fix the Code Then Write Tests

example from CW - complicated factoryWhatever test

should fix the code, not try to somehow test it

TODO of course test-first is better

== Randomness
TODO ref Randomized Tests{empty}pass:[]footnote:[http://wiki.apidesign.org/wiki/RandomizedTests] by Jaroslav Tulach
TODO ref RandomizedTesting{empty}pass:[]footnote:[http://labs.carrotsearch.com/randomizedtesting.html] by Carrot Search Labs

== Help
Send me your tests!

== TODO Book Teaser
TODO

image::images/put_cover.jpg[width="800"]

http://practicalunittesting.com
