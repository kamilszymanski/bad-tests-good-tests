// TODO all source code with tabs

[preface]
About the Author
----------------

*Tomek Kaczanowski* is a technical team leader from Krakow, Poland. He has a strong interest in code quality, testing and automation - preferably all three together. Combining technical with soft skills, he also ventures into the realms of mentoring, teaching, lecturing and article writing, not to mention preaching sermons to the unconverted in the hope of redeeming them (or at least their code)! He hates doing things manually, and is allergic to empty +src/test/java+ directories.

Tomek believes that by working with legacy code, and improving it, he can make the world a better place. To his disappointment, the world does not seem to care all that much about his efforts.

Apart from all this weirdness, he is a pretty normal person â€“ a husband, father of two, and cat owner.

Work in progress
----------------
ifndef::print[]
image::images/72/work_in_progress.png[width="200", float="right"]
endif::print[]
ifdef::print[]
image::images/600/work_in_progress.png[width="200", float="right"]
endif::print[]
The book has not been proofreaded (yet)! There are probably many typos and many language mistakes (my apologies!).

THIS IS WORK IN PROGRESS! Whenever you see a *TODO* word it means that this particular part/sentence/paragraph is not finished.

== Why Bother?
This book is not meant to explain all the reasons of writing tests but there are few things we should know. In short, there are three main reasons for writing tests{empty}pass:[]footnote:[Please forgive the simplifications - I want to make it short!]:

* If we have a complete set of tests, and they all pass, then we know that our application works.
* Making changes is much easier if we have tests. They will inform us if we break some functionality.
* Tests are probably the only documentation we have which stays up-to-date during the whole life of our software.

You should recall these reasons for writing tests when looking at the examples of *bad* tests presented in this book. Ask questions like '"does it test anything?"', '"is it maintainable"', '"is it easy to understand?"' etc.

The worrying thing about writing tests is that there are numerous accounts of people who introduced tests to their development process... and failed! Why? I guess mainly because they lacked knowledge and understanding on how to write good tests. Tests, which are an asset and not a burden.

TIP: Whatever you do, do it good. If it is worth doing, it is worth doing well. Remember this phrases as you write tests!

WARNING: More code written = more code to maintain. It is true also with regards to tests!

== Breaking all The Rules
We will start with some really useless tests. Some of them were written a long time ago (10 years or so), in the era when many of us has probably no bothered to write any tests at all. So with all the respect to the (unknown) authors, today we can say that these tests are bad.

=== No Assertions
These few lines of code are copied from a very old and horrible (truly horrible!) test. Among other things, it had no assertions. Nothing. Null. Zero. Instead, it printed a lot of information to the +System.out+ so that developers could verify whether the tested functionality works or not.

[source,java]
----
IResult result = format.execute();
System.out.println(result.size());
Iterator iter = result.iterator();
while (iter.hasNext()) {
	IResult r = (IResult) iter.next();
	System.out.println(r.getMessage());
}
----

This is of course wrong. Tests should never require us to do any kind of manual verification. No need to browse logs, no need to query a database. Nothing like this. All should happen automatically. A good test fails when the tested functionality is malfunctioning.

A better version is presented below{empty}pass:[]footnote:[Obviously I have no clue what are the expected values, so I made it up.]:

[source,java]
----
IResult result = format.execute();
assertThat(result.size()).isEqualTo(3);
Iterator iter = result.iterator();
while (iter.hasNext()) {
	IResult r = (IResult) iter.next();
	assertThat(r.getMessage()).contains("error");
}
----

=== Autogeneration
Unit tests are simple, right? All they do is they set some object, call its methods, and verify results, right? So, why don't we make computers write them? Hip-hip hurray, we will save a plenty of time, and have 100% code coverage! Let's do it!

...well, it simply does not work, you know. If you think about *why* you really write tests, you will quickly understand that this is a bad idea. It does not help to discover bugs, it does not help you come with better design, it promotes test-last coding and goes against '"test behaviour not methods"' rule (see <<sec_test_behaviour>>). Which really mean that you should not do it. Howgh!

Below is an attempt to autogenerate some test code (using JUnitDoclet tool{empty}pass:[]footnote:[Nope, not link to project website this time, because I do not think you should use it. :)]). As you can see it successfully generated tests for getters/setters, which is, shortly speaking, a waste of time.

[source,java]
----
public void testSetGetTimestamp() throws Exception {
    // JUnitDoclet begin method setTimestamp getTimestamp
    java.util.Calendar[] tests = {new GregorianCalendar(), null};

    for (int i = 0; i < tests.length; i++) {
    	adapter.setTimestamp(tests[i]);
    	assertEquals(tests[i], adapter.getTimestamp());
    }
    // JUnitDoclet end method setTimestamp getTimestamp
}

public void testSetGetParam() throws Exception {
    // JUnitDoclet begin method setParam getParam
    String[] tests = {"a", "aaa", "---", "23121313", "", null};

    for (int i = 0; i < tests.length; i++) {
    	adapter.setParam(tests[i]);
    	assertEquals(tests[i], adapter.getParam());
    }
    // JUnitDoclet end method setParam getParam
}
----

What kind of bugs do you expect to discover by such tests?

So now repeat after me: '"I will not autogenerate neither the test code, nor its skeleton. I will not autogenerate neither the test code, nor its skeleton. I will not autogenerate neither the test code, nor its skeleton. I will not autogenerate neither the test code, nor its skeleton..."' (pretty useful mantra if you can't fall asleep, should help after 1000 repetitions).

TIP: Do *NOT* autogenerate neither the test code, nor it skeleton.

=== It is a Full Time Job
[verse, Eddy Arnold, from "A Full Time Job"]
____
I want a life time job bein' close to you
Makin' all your dreams come true
But if your heart don't throb about a full time job
A part time job will do
____

Let's face it - writing tests makes sense only if you (and your team) take care about them every day. In this section I present two examples of what happens when it is no so.

First is a short snippet of +SystemAdminSmokeTest+ class. *Smoke test*, mind you, which means this is an important test that intends to give you quick feedback about the health of the system. This test at the time I joined this project looked as follows. Please note that all the lines all commented out!

[source,java]
----
class SystemAdminSmokeTest extends GroovyTestCase {

void testSmoke() {
// do not remove below code
// def ds = new org.h2.jdbcx.JdbcDataSource(
//     URL: 'jdbc:h2:mem:test;DB_CLOSE_DELAY=-1;MODE=Oracle',
//     user: 'sa', password: '')
//
//     def jpaProperties = new Properties()
//     jpaProperties.setProperty(
//			'hibernate.cache.use_second_level_cache', 'false')
//     jpaProperties.setProperty(
//			'hibernate.cache.use_query_cache', 'false')
//
//     def emf = new LocalContainerEntityManagerFactoryBean(
//        dataSource: ds, persistenceUnitName: 'my-domain',
//        jpaVendorAdapter: new HibernateJpaVendorAdapter(
//            database: Database.H2,  showSql: true,
//            generateDdl: true), jpaProperties: jpaProperties)

   ...
}
----

Well, it is not gonna inform anyone about the state of the system... I guess there was a time when this test used to work. But then some changes came and it was commented out (I bet it was commented out only '"for a very short time"'....) and it was never brought to life again. A pity, yes. And a rather discouraging sign to anyone joining the team{empty}pass:[]footnote:[Which was misleading BTW, because the project and the team were doing pretty well!].

Another example is even more depressing. In one of the modules of some project I found this test in +src/test/java+ directory:

[source,java]
----
@Test
public class ExampleTest {

	public void testExample() {
		assertTrue(true);
	}
}
----

I think you've already guessed the end of this story. Yes, that was the only test there...

And what can we learn from these two failures? Few things:

* Do not live with '"broken windows"'{empty}pass:[]footnote:[See http://c2.com/cgi/wiki?FixBrokenWindows]; fix things immediately!
* Writing and maintaining tests is an effort which has to be taken by the whole team (and this effort must be also supported, or at least not hindered, by all stakeholders).
* Good intentions are not enough. You also need knowledge, time and determination to meet the goal of well-tested software.

=== Conclusions
There are few things that we can learn from the attempts to write tests presented so far:

* automation is the king! 
* write tests, do not generate them!
* writing tests is a full-time job and there is noone else that will do it for you,
* do not live with broken windows - fix things as soon as they break.

Armed with this basic knowledge we can now move to some more interesting examples.

== Do Not Modify Global State
For unit tests a rule of thumb is to keep them independent from each other. It is not so bad if we introduce a dependency on purpose (and explicitly declare it e.g. using TestNG +dependsOnMethod+ feature). A worse scenario is when we are not aware of the dependency ourselves. This can bring serious problems on our heads.

TIP: Keep your tests independent from each other. Or at least make the dependency explicit!

Let us have a look at the following example. The test presented below verifies whether log4j{empty}pass:[]footnote:[http://logging.apache.org/log4j/] configuration code works fine. If some system property (+logConfig+) is available, it should load file specified by this property. If the property is not set it should load some default values.

[source,java]
----
LoggingPropertyConfigurator configurator 
	= mock(LoggingPropertyConfigurator.class);
BaseServletContextListener baseServletContextListener 
	= new BaseServletContextListener(configurator);

@Test
public void shouldLoadDefaultProperties() {
	baseServletContextListener.contextInitialized(null);
	verify(configurator).configure(any(Properties.class));
}

@Test(expected = LoggingInitialisationException.class)
public void shouldThrowLoggingException() {
	System.setProperty("logConfig", "nonExistingFile");
	baseServletContextListener.contextInitialized(null);
}
----

This test used to be [green]#green# for months. Then suddenly (after some completely unrelated commit) it turned [red]#red#. Why?! For no apparent reason, the log4j config was not something we changed often. In fact, we haven't touched it for a long time...

After some digging we have found out that the test failed because the order of execution of tests changed. As long as the +shouldLoadDefaultProperties()+ method was executed before the +shouldThrowLoggingException()+ method everything was fine. But once this order was changed, things started to go wrong. In particular, the +logConfig+ system property was set when the +shouldLoadDefaultProperties()+ test was executed which altered the behaviour of SUT and made this test fail.

And why did the order of execution changed? Well, it does not really matter. In general test frameworks do not guarantee the order of execution (unless you explicitly ask for it) so you should not rely on this.

TIP: Be extra cautious when modifying 'global state' (system properties, file system, database etc.) in your tests. This can influence other tests. Take care to make sure that tests execute in well-defined environment!

Now, how to fix it. Basically there are two solutions.

First, you can impose strict order of execution of these two test methods (TestNG will allow you to do this, JUnit won't).

// TODO does it work

[source,java]
----
@Test
public void shouldLoadDefaultProperties() { ... }

@Test(expected = LoggingInitialisationException.class,
	dependesOnMethod = "shouldLoadDefaultProperties")
public void shouldThrowLoggingException() { ... }
----

This works as long as there are no more tests which outcome also depend on the value of +logConfig+ system property. If such tests are added you need to remember to also specify their relation (their dependency) to these existing tests. Which means you can end up with a web of tests depending on each other which is not easy to maintain.

Another option (and a recommended one) is to clean +logConfig+ system property variable before the +shouldLoadDefaultProperties()+ method is executed. If there are more tests like this then maybe putting the 'cleaning' code some +setUp()+ method would be a good idea. For example:

// TODO does it work
[source,java]
----
@BeforeMethod
public void cleanSystemProperties() {
	System.setProperty("logConfig", null);
}

// the rest of the code remains unchanged
----

TIP: Clean the environment *before* tests, not after it. This way your tests are guaranteed to run in clean environment. 

// TAGS: GLOBAL STATE, CLEAN UP

[[sec_mock_em_all]]
== Mock'em All!
[quote, Abraham Maslow]
_______________________
To a man with a hammer everything looks like a nail.
_______________________

This is something I observe frequently among developers who has only recently discovered the pleasures of mocking. :) They tend to overuse all kind of test doubles even when it is not really the best option. Let us see an example.

The code below intends to verify whether some data is added to +modelAndView+ object{empty}pass:[]footnote:[This is +ModelAndView+ from Spring MVC framework.]. Yes, you heard it right: it verifies whether something is *added*.

[source,java]
----
@Test
public void shouldAddTimeZoneToModelAndView() {
	//given
	UserFacade userFacade = mock(UserFacade.class);
	ModelAndView modelAndView = mock(ModelAndView.class);
	given(userFacade.getTimezone()).willReturn("timezone X");

	//when
	new UserDataInterceptor(userFacade)
		.postHandle(null, null, null, modelAndView);

	//then
	verify(modelAndView).addObject("timezone", "timezone X");
}
----

The problem with this test is, that what we really care about is whether +modelAndView+ contains certain data, not whether some methods of +modelAndView+ were called! It does not seem to be such a big deal. If it was added then it is probably there, so what is the problem? Right. This test is probably doing its job in verifying that the +modelAndView+ object ends up with +timezone+ set. However as a rule, we should try to verify the outcome, not the way it was achieved. Why? Because this way we leave the possibility to change the implementation details of the tested class without breaking the test.

I will give you an example (even if it is not true in relation to the +ModelAndView+ API). Should we care whether the +timezone+ property was set like this:

[source,java]
----
ModelAndView mav = new ModelAndView();
mav.addObject("timezone", "timezone X");
----

or like this:

[source,java]
----
ModelAndView mav = new ModelAndView("timezone", "timezone X");
----

Is it really important for us, who are interested in the fact of +timezone+ being available? I think not. And the test also shouldn't. Still the version of the test we have just discussed does exactly this: dictates the SUT how it should do things.

Below you can see an improved version of this test. It treates SUT more like a black box and only cares about its output.

[source,java]
----
@Test
public void shouldAddTimeZoneToModelAndView() {
	//given
	UserFacade userFacade = mock(UserFacade.class);
	ModelAndView modelAndView = new ModelAndView();
	given(userFacade.getTimezone()).willReturn("timezone X");

	//when
	new UserDataInterceptor(userFacade)
		.postHandle(null, null, null, modelAndView);

	//then
	assertThat(modelAndView).contains("timezone", "timezone X"); <1>
}
----
<1> There is no +contains()+ methods like this, but this is the assertion we would like to have.

As you can see in the second version we use real object, not a test double. And this is fine, because +ModelAndView+ is not a service, but a container for data, which should not be mocked. Howgh!

TIP: Excited that you can mock everything, huh? Slow down and make sure that you really need to verify interactions. Chances are you don't.

// TAGS: UNNECESSARY MOCKS, INTERACTION INSTEAD OF STATE TESTING

== Mocks Are Good
And now the opposite of what was presented in the previous section (<<sec_mock_em_all>>).

In the following test four objects are created. One of them is a mock of the +TrafficTrendProvider+ class, which is used by the SUT (object of the +TrafficService+ class). The remaining two are real objects created using the +new+ keyword. If we look closer we can notice that the +report+ variable is used solely for the creation of the other real object - +trafficTrend+.

[source,java]
----
@Test
public void shouldGetTrafficTrend() {
	//given
	TrafficTrendProvider trafficTrendProvider = mock(TrafficTrendProvider.class);
	Report report = new Report(null, "", 1, 2, 3, BigDecimal.ONE, BigDecimal.ONE, 1);
	TrafficTrend trafficTrend = new TrafficTrend(report, report,
		new Date(), new Date(), new Date(), new Date());
	given(trafficTrendProvider.getTrafficTrend()).willReturn(trafficTrend);
	TrafficService service = new TrafficService(trafficTrendProvider);

	//when
	TrafficTrend result = service.getTrafficTrend();

	//then
	assertThat(result).isEqualTo(trafficTrend);
}
----

The major issue with this test is that it creates real objects which are irrelevant to the tested scenario! This is bad because the test becomes very fragile this way. Any change in constructor of the +Report+ or +TrafficTrend+ classes and the tests needs to be updated. +
Another downside of this test is that it distracts the reader from the testing scenario by providing too many details which are not important at all. For example, what is the empty +String+ parameter (+""+) of the +Report+ constructor, and does it matter that there are four identical dates passed to the second constructor?

Instead I would suggest to cut this blah-blah to the minium and use mocks instead of real objects.

[source,java]
----
@Test
public void shouldGetTrafficTrend() {
	//given
	TrafficTrendProvider trafficTrendProvider = mock(TrafficTrendProvider.class);
	TrafficTrend trafficTrend = mock(TrafficTrend.class);
	given(trafficTrendProvider.getTrafficTrend()).willReturn(trafficTrend);
	TrafficService service = new TrafficService(trafficTrendProvider);

	//when
	TrafficTrend result = service.getTrafficTrend();

	//then
	assertThat(result).isEqualTo(trafficTrend);
}
----

This test does not distract the reader by providing only what is important to verify the tested scenario. It uses mocks instead of real objects which makes it less fragile than its previous version.

TIP: Creating objects only to create other objects so you can create other objects? Do not do that! (Unless the creation of objects is what you want to test).

// TAGS obscure SETUP, CREATION OF OBJECTS

[[sec_time_means_troubles]]
== Time Means Troubles (Always!)
TIP: As a rule *never* use +System.currentTimeMillis()+ or +new Date()+ in your production code. Add an additional layer of abstraction - e.g. a +DateTimeProvider+ interface. This will let you test your time-dependent methods with ease.

Let us see what happens when you do not follow this advice.

An obvious example would look like this:

[source,java]
----
time = System.currentTimeMillis();

if (time.isAfter(5, PM)) {
	... do some afternoon activity
}
else {
	... do somethig else
}
----

Well, this one is obvious - you can't test all paths util you control the value of time variable.

But let us see a real, slightly more subtle example. Let us take a look at this fragment of production code (the +Util+ class):

[source,java]
----
public String getUrl(User user, String timestamp) {
	String name=user.getFullName();

	String url=baseUrl
		+"name="+URLEncoder.encode(name, "UTF-8")
		+"&timestamp="+timestamp;
	return url;
}

public String getUrl(User user) {
	Date date=new Date();
	Long time=(date.getTime()/1000); //convert ms to seconds
	String timestamp=time.toString();
	return getZendeskUrl(user, timestamp);
}
----

Testing of such methods should be straightforward - they return some +String+ which we could analyze and verify its correctness. Alas, because the +new Date()+ was used, the programmer responsible for this code was not able to verify the resulting URL. Instead, he came up with the following test:

[source,java]
----
@Test
public void shouldUseTimestampMethod() {
        //given
	Util util = new Util();
        Util spyUtil = spy(util);

        //when
        spyUtil.getUrl(user);

        //then
        verify(spyUtil).getUrl(eq(user), anyString());
}
----

Oh my, this is bad for few reasons. This test:

* tests implementation instead of behaviour (see <<sec_test_behaviour>>),
* uses partial mocking (+spy+ method on real object) which is rarely required (a [red]#red# lamp should start blinking in your head when you see it),
* verifies interactions instead of returned values.

And all of this because the production code does not handle properly time!

TIP: See <<sec_fix_the_code_first>> for some more examples of writing tests instead of fixing the code first!

After we redesign the production code by replacing call to +new Date()+ with a call to some collaborator, our test starts looking pretty nice:

[source,java]
----
@Test
public void shouldAddTimestampToGeneratedUrl() {
	//given
	Util util = new ....
	TimeProvider timeProvider = mock(TimeProvider.class);
	when(timeProvider.getTime()).thenReturn("12345");
	util.set(timeProvider);

	//when
	String url = util.getUrl(user);

	//then
	assertThat(url).contains("timestamp=12345");
}
----

TIP: If tested method return some values then try to use this values to verify whether the method works fine. Use mocks/spies only if it is really required{empty}pass:[]footnote:[Please note that the +shouldAddTimestampToGeneratedUrl+ method does not use mocks but a stub only!].

// TAGS INTERACTIONS INSTEAD OF STATE TESTING, BAD CODE -> BAD TESTS

[[sec_srp]]
== SRP for Tests
[verse, Natasha Bedingfield, from "Single"]
____
I'm single
(Right now)
That's how I wanna be
____

We are all familiar with Single Responsibility Principle{empty}pass:[]footnote:[SRP, see http://en.wikipedia.org/wiki/Single_responsibility_principle], which basically says that every class should take care of one thing. I think it is very valuable to think about tests in terms of SRP. In case of tests, each test method should conform to the following rule: '"Each test method should verify one scenario"'.

Why? Because:

* such test methods are pretty simple to understand,
* if they fail you know *exactly* which functionality of your software does not work.

NOTE: Writing tests which fullfil the SRP principle is very simple for unit tests, but not always reasonable for other kind of tests. Sometimes you will want to verify few things in one test because of the setup cost.

Still, I observe it being breached frequently. In this section we will take a closer look at some examples.

// TAGS: SRP, NO LOGIC, METHOD NAMES

=== True and False
Let us have a look at an example. It comes from a simple utility class, which was responsible for making sure that the phone prefix entered by users are valid.

[source,java]
----
@DataProvider
public Object[][] data() {
	return new Object[][] { {"48", true}, {"+48", true}, 
		{"++48", true}, {"+48503", true}, {"+4", false},
		{"++4", false}, {"", false},
		{null, false}, {"  ", false}, };
}

@Test(dataProvider = "data")
public void testQueryVerification(String query, boolean expected) {
	assertEquals(expected, FieldVerifier.isValidQuery(query));
}
----

At the first sight, it may seem like the test is really focused on one thing (on the verification of query validity), but if you look closer you will see some alarming signals:

* its method name is quite generic, and it would be hard to use a '"should"' prefix (see <<sec_should>>),
** also the name of data provider{empty}pass:[]footnote:[A 'data provider' is a method which provides data for test cases. See TestNG's +@DataProvider+ annotation or JUnitParams project - +data+ - smells really bad,
* it has some kind of logic: assertions depends on passed +expected+ boolean flag,
* a "generic" assertion - +assertEquals+ - is used to verify the outcome.

//(see <<sec_no_logic>>).

To discover if your test fulfills SPR ask the following question: '"if it fails will I be able to discover what fuctionality of my software is broken just by reading the name of the failed test method?"'.

Here is the same tests (meaning, test which verifies exactly the same scenarios) but divided into two parts:

[source,java]
----
@DataProvider
public Object[][] validQueries() {
	return new Object[][] { {"48"}, {"48123"}, 
		{"+48"}, {"++48"}, {"+48503"}};
}

@Test(dataProvider = "validQueries")
public void shouldRecognizeValidQueries(String validQuery) {
	assertTrue(FieldVerifier.isValidQuery(validQuery));
}

@DataProvider
public Object[][] invalidQueries() {
	return new Object[][] {
		{"+4"}, {"++4"},
		{""}, {null}, {"  "} };
}

@Test(dataProvider = "invalidQueries")
public void shouldRejectInvalidQueries(String invalidQuery) {
	assertFalse(FieldVerifier.isValidQuery(invalidQuery));
}
----

This version is longer, but more readable, easier to understand (no boolean flag), and it follows the SRP rule. What I really like here are the names - all of them describe very well the purpose of elements. We have a data provider which provides +validQueries+, and a test method which takes +validQuery+ as a parameter.

TIP: Watch the method names. Are they intention-revealing?

TIP: No logic in tests! Even the simplest one is evil!

[[sec_test_behaviour]]
=== Test Behaviour Not Methods!
Now another example of a test doing too much. Let us look at the tested method first. This is a part of the +UserRegisterController+ class.

[source,java]
----
public ModelAndView registerUser(UserData userData, BindingResult result, HttpServletRequest request) {
	if (result.hasErrors()) {
		return showRegisterForm(request, false);
	}

	User savedUser = userService.saveNewUser(userData.toEntity());
	mailSender.sendRegistrationInfo(savedUser);
	return new ModelAndView("redirect:/signin");
}
----

Let us assume that all tests presented below have the following variables initialized properly;

[source,java]
----
// sut
UserRegisterController userRegisterController = ... // object created;

// mocks
UserData userData = mock(UserData.class);
UserService userService = mock(UserService.class);
BindingResult bindingResult = mock(BindingResult.class);
User user = mock(User.class);
----

Now let us have a look at the original test.

NOTE: I had to simplify the original test to make the essence of what we discuss here more clear. Unfortunately this also made the effect of the changes we will introduce less visible. :(

[source,java]
----
@Test
public void shouldReturnRedirectViewAndSendEmail() {
	//given
	given(bindingResult.hasErrors()).willReturn(false);
	given(userData.toEntity()).willReturn(user);
	given(userService.saveNewUser(eq(userData.toEntity()))).willReturn(user);

	//when
	ModelAndView userRegisterResult = userRegisterController.registerUser(userData, bindingResult, request);

	//then
	assertThat(userRegisterResult.getViewName()).isEqualTo("redirect:/signin");
	verify(mailSender).sendRegistrationInfo(user);
}
----

As you can see this test verifies exactly what the tested method does. Which means it verifies two expectations:

* that the +sendRegistrationInfo()+ of the +mailSender+ object will be invoked with specific parameter (+user+ object),
* that the user (the user who fill in the registration form, not the +user+ object!) will be redirected to specific page.

It also indirectly verifies whether the +user+ object is stored by the +userService+ collaborator.

This is not bad. In fact this test does a decent job. My advice however would be to split it into two parts, like this:

[source,java]
----
@Test
public void shouldRedirectToSigninPageWhenBindingResultsHasNoErrors() {
	//given
	given(bindingResult.hasErrors()).willReturn(false);

	//when
	ModelAndView redirectMav = userRegisterController.registerUser(userData, bindingResult, request);

	//then
	assertThat(redirectMav.getViewName()).isEqualTo("redirect:/signin");
}
----

This first test verifies solely whether the redirect is fine.

[source,java]
----
@Test
public void shouldNotifyAboutNewUserRegistration() {
	//given
	given(bindingResult.hasErrors()).willReturn(false);
	given(userData.toEntity()).willReturn(user);
	given(userService.saveNewUser(eq(userData.toEntity()))).willReturn(user);

	//when
	biddingRegisterController.registerSubmit(userData, bindingResult, request);

	//then
	verify(mailSender).sendRegistrationInfo(user);
----

The second test verifies whether the +sendRegistrationInfo()+ method of the +mailSender+ object was invoked.

The main difference between the first presented version and the one we have now, is that the first one tried to *test method* while the latter *tests responsibility* of the class. The current version consists of two tests, and each of them is focused on one responsibility of the tested class. The class should redirect user to a specific page after the successful registation. And there is a test which verifies it. Some actors should be notified about the fact of the successful registration - and there is a test which verifies whether a specific collaborator was asked for it. I'm sure the responsibility of the class does not end there (for example I guess it also prints errors when the registration form lacks some data). Good. We can always add more tests to cover the rest of responsibilities. Responsibilities, not methods!

By analogy to the production code we should try to keep our tests small and focused. We should also abstract from the implementation so the refactorings does not break the tests. The changes we have just introduced to the initial test allowed us to achieve both. The tests are so focused that some modifications of the +registerSubmit+ method implementation might fail only a selected test. Then it will be very simple to see what is not working anymore. I like it.

TIP: Forget about methods. Test responsibilities of the class.

TIP: A simple rule to follow: '"One method, multiple behaviours? Multiple tests!"'.

=== A Counter Example
And now, a counter example. Yes, after I have tried to convince you that it is good to split tests into smaller ones (each testing a unique test case), I will show an example of the opposite approach.

Take a look at the test method below:

[source,java]
----
@Test
public void shouldRecognizeSameCampaign() {
	//given
	Campaign otherCampaign = mock(Campaign.class);
	Campaign campaign = mock(Campaign.class);

	//when
	CampaignBid cBid = new CampaignBid(campaign, VALID_BID);

	//then
	assertThat(cBid.hasSameCampaign(otherCampaign)).isFalse();
	assertThat(cBid.hasSameCampaign(campaign)).isTrue();
}
----

It verifies two things, namely:

* whether +CampaignBid+ is capable of recognizing the same domain (which it was constructed with - I haven't presented the constructor, but it takes +Domain+ as one of parameters),
* whether +CampaignBid+ is capable of recognizing domains which are different from the one it was constructed with.

Should we split it in two tests then? My answer is no.

In contrast to the previous example, there are not many cases to test here, so the test method is very concise and simple to understand. In other words, the size of this method (taking into account the number of test cases it verifies, not only number of lines it has) has not exceeded my private safety limit. And thus, I do not feel like having two testing methods instead.

Let us have a look at two-methods version for comparison:

[source,java]
----
@Test
public void shouldRecognizeSameCampaign() {
	//given
	Campaign campaign = mock(Campaign.class);

	//when
	CampaignBid cBid = new CampaignBid(campaign, VALID_BID);

	//then
	assertThat(cBid.hasSameCampaign(campaign)).isTrue();
}

@Test
public void shouldRecognizeDifferentCampaign() {
	//given
	Campaign otherCampaign = mock(Campaign.class);
	Campaign campaign = mock(Campaign.class);

	//when
	CampaignBid cBid = new CampaignBid(campaign, VALID_BID);

	//then
	assertThat(cBid.hasSameCampaign(otherCampaign)).isFalse();
}
----

Make your own decision about this and choose the approach which suits you better.

TIP: Rules are to be broken. ;)

////
another SRP-violating example: http://stackoverflow.com/questions/4152539/how-do-i-test-exceptions-in-a-parameterized-test
////

////
[[sec_no_logic]]
== Logic in Tests
TODO need some good examples of this

avoid by using some features of your testing framework - annotations data provider instead of for loops (TODO ref) and concurrent with annotations

TODO refer to SRP - boolean is also kind of logic
////

// TAGS EXCEPTION, SRP
== Localized Exceptions
The next test that I would like to discuss comes from an online tutorial (you should really watch out which tutorials you read...). It is an awful test with more than one issue. We will concentrate on one part of it, namely the way the exceptions are tested.

[source,java]
----
@Test(expected=IndexOutOfBoundsException.class)
public void testMyList() {
	MyList<Integer> list = new MyList<Integer>();
	list.add(1);
	list.add(2);
	list.add(3);
	list.add(3);
	list.add(4);
	assertTrue(4 == list.get(4));
	assertTrue(2 == list.get(1));
	assertTrue(3 == list.get(2));
    
	list.get(6);
}

@Test(expected=IndexOutOfBoundsException.class)
public void testNegative() {
	MyList<Integer> list = new MyList<Integer>();
	list.add(1);
	list.add(2);
	list.add(3);
	list.add(3);
	list.add(4);
	list.get(-1);
}
----

What is important here is that these two test methods are the only ones which verify whethere the +MyList+ class works fine.

As you have noticed both test methods are decorated with +@Test(expected=IndexOutOfBoundsException.class)+ which means they will not pass if this exception is not thrown. Unfortunately both *will pass* if such exception is thrown at any point of test method executions. This all boils down to this, that even such flawed implementation of the +MyList+ class as presented below passes both test methods with flying colors.

[source,java]
----
public class MyList<T> {

    public MyList() {
        throw new IndexOutOfBoundsException();
    }

    public void add(T i) {
    }

    public T get(T i) {
        return null;
    }
}
----

Well, this is embarassing... Apparently we need to do something about the exception verification. There are two main techniques we could use. First is to split the test into few smaller tests (see <<sec_srp>>). Second is to better localize the exception.

The first approach would result in few small test methods each of them occupied with different functionality of the +MyList+ class, like +shouldKeepValuesInOrder+ or +shouldAcceptDuplicateValues+ and so on. Now having this verified we would also create a test method especially for the verification of what happens when we try to retrieve element which is not there. Like this:

[source,java]
----
@Test(expected=IndexOutOfBoundsException.class)
public void shouldThrowExceptionWhenTryingToGetElementOutsideTheList() {
	MyList<Integer> list = new MyList<Integer>();
	list.add(0);
	list.add(1);
	list.add(2);
	list.get(3);
}
----

This does not differ much from the original test, but thanks to having other test methods we are in much safer position. We *know* the constructor and basic +add+/+get+ functionality works, so we can assume the +IndexOutOfBoundsException+ will be cause by the last line of this test method.

The other approach says we should localize the exception. To do it we need to get rid of the +expected+ attribute of the +@Test+ annotation which is satisfied when an exception thrown at any point of the test method.

The first thing we could do is to use the +try-catch+ statement and fail the test if we do not enter the +catch+ clause. However, there are some nicer options.

The solution presented below makes good use of:

* the catch-exception library{empty}pass:[]footnote:[See http://code.google.com/p/catch-exception/] which offers the +catchException()+ and the +caughtException()+ methods which are exactly what we need,
* nice DSL provided by FEST Assert to examine the exception within the +catch+ clause.

[source,java]
----
@Test
public void shouldThrowExceptionWhenTryingToGetElementOutsideTheList() {
	MyList<Integer> list = new MyList<Integer>();
	list.add(0);
	list.add(1);
	list.add(2);

	catchException(list).get(3);
	assertThat(caughtException()).isExactlyInstanceOf(IndexOutOfBoundsException.class);
}
----

Now there is no doubt about where the exception comes from! We can pinpoint it with great accuracy and the result of the test will leave no doubt about the source of exception.

TIP: Catch-exception is quite handy. Consider using it everywhere instead of annotation or +try-catch+ statement.

== Be Generic
Once upon a time there was a servlet which took two parameters - packet and type. If both were present in a request then the servlet asked its collaborator - +packetDataProcessor+ - to process a specific packet. If one or both of the parameters were missing no processing should occur. Simple, isn't it?

Let us start with a "happy path" test which verifies the behaviour of the servlet when both parameters are present (and valid).

[source,java]
----
@Test
public void shouldProcessPacket() throws IOException, ServletException {
	//given
	given(request.getParameter(PacketApiServlet.PACKET_PARAMETER)).willReturn(PACKET);
	given(request.getParameter(PacketApiServlet.TYPE_PARAMETER)).willReturn(TYPE);

	//when
	servlet.doGet(request, response);

	//then
	verify(packetDataProcessor).process(PACKET, TYPE);
}
----

This one looks good to me. I would probably give it a little more descriptive name, but apart from this minor issue, it is perfect.

But let us look at the next tests.

[source,java]
----
@Test
public void shouldNotProcessIfPacketParameterIsMissing() throws IOException, ServletException {
	//given
	given(request.getParameter(PacketApiServlet.TYPE_PARAMETER)).willReturn(TYPE);

	//when
	servlet.doGet(request, response);

	//then
	verify(packetDataProcessor, never()).process(PACKET, TYPE);
}
----

So this is a "negative" case. One of the required parameters is missing and there should be no processing. Seems ok, but... there is one thing bothering me. Why the verification assumes that the +packetDataProcessor+ could be asked to process +PACKET+? This value does not appear anywhere in the test so why the verification uses it? Aha! It does not appear in the test, but it surely is still in the head of the developer who wrote the previous test (see the previous listing).

Anyway, this is too specific. I would suggest that this test took a form of '"if one of the required parameters is missing then +packetDataProcessor+ should process nothing"', which, after translation into Java/Mockito/JUnit language looks like this:

[source,java]
----
@Test
public void shouldProcessIfPacketParameterIsMissing() throws IOException, ServletException {
	//given
	given(request.getParameter(PacketApiServlet.TYPE_PARAMETER)).willReturn(TYPE);

	//when
	servlet.doGet(request, response);

	//then
	verifyZeroInteractions(packetDataProcessor);
}
----

The +verifyZeroInteractions+ method of Mockito is exactly for such purposes. We want to know that there were no calls to +packetDataProcessor+ because a validation mechanism should reject incomplete request beforehand.

Another example from the same test class. This time it is about the servlet's behaviour after a processing error. 

[source,java]
----
@Test
public void shouldReturnStatus500IfThereWasAnErrorDuringProcessing() throws IOException, ServletException {
	//given
	given(request.getParameter(PacketApiServlet.PACKET_PARAMETER)).willReturn(PACKET);
	given(request.getParameter(PacketApiServlet.TYPE_PARAMETER)).willReturn(TYPE);
	doThrow(NullPointerException.class).when(packetDataProcessor).process(PACKET,TYPE);

	//when
	servlet.doGet(request, response);

	//then
	verify(response).setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);
}
----

This test verifies the behaviour of the servlet in case of the +NullPointerException+ thrown when processing. Hmm... why from the plethora of exceptions +NPE+ was selected? It is hard to say. I took a look into the implementation of +packetDataProcessor+ and found out that it throws some parsing exceptions when trying to process a garbaged data. Having a test which concentrates on +NPE+ solely does not tell us what happens when different exceptions are thrown. Which is bad.

Similarly to the previous example this test is too specific. Instead of verifying whether status code 500 is set in case of the +NullPointerException+ it really should verify whether this status code is returned in case of *any* exception during processing (as shown below).

[source,java]
----
@Test
public void shouldReturnStatus500IfThereWasAnErrorDuringProcessing() throws IOException, ServletException {
	//given
	given(request.getParameter(PacketApiServlet.PACKET_PARAMETER)).willReturn(PACKET);
	given(request.getParameter(PacketApiServlet.TYPE_PARAMETER)).willReturn(TYPE);
	doThrow(Exception.class).when(packetDataProcessor).process(PACKET,TYPE);

	//when
	servlet.doGet(request, response);

	//then
	verify(response).setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);
}
----

TIP: Do not be too specific. It will make your test less valuable by examining only a subset of test cases.
 
== Use Smart Values
// TODO obfuscate
Try to minimize the risk of having your tests pass by accident. And always work to improve the readability.

Let us consider the following factory method:

[source,java]
----
public PayoutCalculator create() {
	BigDecimal minMargin = settings.getMinMargin();
	BigDecimal maxMargin = settings.getMaxMargin();
	BigDecimal premiumShare = settings.getPremiumShare();
	return new PayoutCalculator(minMargin, maxMargin, premiumShare);
}
----

+settings+ is a collaborator, and as such should be stubbed in test.

This test does exactly this:

[source,java]
----
public class PayoutCalculatorFactoryTest {
	PayoutSettingsService settings = mock(PayoutSettingsService.class);

	@Test
	public void shouldCreatePayoutCalculator() {
		//given
		given(settings.getMinMargin()).willReturn(new BigDecimal(20));
		given(settings.getMaxMargin()).willReturn(new BigDecimal(50));
		given(settings.getPremiumShare()).willReturn(new BigDecimal(50));

		//when
		PayoutCalculator calculator = new PayoutCalculatorFactory(settings).create();

		//then
		assertThat(calculator)
			.isEqualTo(new PayoutCalculator(new BigDecimal(20), 
			new BigDecimal(50), new BigDecimal(50)));
	}
}
----

Even if the values used in test (+minMargin+ = 20, +maxMargin+ = 50, +premiumShare+ = 50) makes business sense, they should not be used in test. Why? Because there is always a chance, that the tested method is flawed and values are improperly assigned (this can happen if someone created it with *copy&paste* approach). Imagine the +maxMargin+ parameter is assigned to +premiumShare+ and vice versa. This test would still pass even in case of such implementation error.

To minimize the risk use different values for each parameter. The following code shows this (also there is some refactoring done so the values are extracted as +static final+ fields):

[source,java]
----
public class PayoutCalculatorFactoryTest {
	PayoutSettingsService settings = mock(PayoutSettingsService.class);
	
	private static final BigDecimal MIN_MARGIN = new BigDecimal(20);
	private static final BigDecimal MAX_MARGIN = new BigDecimal(30);
	private static final BigDecimal PREMIUM_SHARE = new BigDecimal(40);

	@Test
	public void shouldCreatePayoutCalculator() {
		//given
		given(settings.getMinMargin()).willReturn(MIN_MARGIN);
		given(settings.getMaxMargin()).willReturn(MAX_MARGIN);
		given(settings.getPremiumShare()).willReturn(PREMIUM_SHARE);

		//when
		PayoutCalculator calculator = new PayoutCalculatorFactory(settings).create();

		//then
		assertThat(calculator)
			.isEqualTo(new PayoutCalculator(MIN_MARGIN, MAX_MARGIN, PREMIUM_SHARE);
	}
}
----

TIP: Avoid using same numbers/strings for different variables/properties in your tests method! Often power of 2 are quite convenient (they do not sum up to each other easily).

== Database Assumptions
Take a look at this test:

[source,java]
----
@Test
public void shouldAddUser() {
	User user = new User();
	userService.save(user);
	assertEquals(dao.getNbOfUsers(), 1);
}
----

The test looks like an integration test (seems like +userService+ and +dao+ talk with real database), which adds a new user to the database.

What is bothering me here is that:

1. it does not really verify if the user was added,
2. it makes some assumptions regarding the state of the database before it is executed,

Regarding the first point, this should be probably done by verifying that the user in the database is equal to the +user+ object. This can be straigforward provided that +userService+ or +dao+ provides appropriate method(s) to fetch the user, or can require much more work (e.g. writing custom JDBC queries directly to database and parsing results in your test code... yuck!).

As for the second issue the solution is quite simple - replace absolute values with relative ones:

[source,java]
----
@Test
public void shouldAddUser() {
	int nb = dao.getNbOfUsers();
	User user = new User();
	userService.save(user);
	assertEquals(dao.getNbOfUsers(), nb + 1);
}
----

Now the content of the test method reflects its name (+shouldAddUser()+). Good.

It happened that such assumption about the database state (i.e. the assumption that there are no users at all at the beginning of the test) caused some additional work for my team some time ago. At some point it occured that we need to add a 'fake' user to the system (the reason was to handle some extra-cases so it was easier to filter them out from reports etc.). And this user had to be always available. So we created a database patch which added this fake user to the system. It was applied along with all other patches to se the database in the initial state before integration tests were run. And then we observed (with amazement) that many tests started to fail. Why? Because they assumed that the database has no users at all!

TIP: Do not make assumptions about the database content. Use relative rather than absolute values.

TIP: Make sure the test does exactly what its (method) name promises.

== Self-Test
In one application there was a need to implement many payment methods. Their list, along with the information about the countries where each method is accepted, was kept by the +PaymentMethod+ enum.

The test below verifies whether the +getMethodsForCountry()+ method of the +PaymentMethod+ class returns valid methods for Poland. First it creates the list of expected payment methods, then calls the method in question, and eventually compares expected list with the result of the tested method invocation.

[source,java]
----
@Test
public void shouldGetMethodsForPoland() {
	//given
	List<PaymentMethod> all = Lists.newArrayList(PaymentMethod.values());
	List<PaymentMethod> methodsAvailableInPoland = Lists.newArrayList();
	for (PaymentMethod method : all) {
		if (method.isEligibleForCountry("PL")) {
			methodsAvailableInPoland.add(method);
		}
	}

	//when
	List<PaymentMethod> methodsForCountry = PaymentMethod
		.getMethodsForCountry(new CountryBuilder().withCode("Pl").build(), all);

	//then
	assertThat(methodsForCountry).isEqualTo(methodsAvailableInPoland);
}
----

The test seems right... but there is something disturbing about its +given+ part. It uses two methods of the +PaymentMethod+ enum (+values()+ and +isEligibleForCountry()+) in order to prepare the list of expected methods. Let us have a look now at the implementation of the +getMethodsForCountry()+ method to see if our fears are justified.

[source,java]
----
public enum PaymentMethod {

	public static List<PaymentMethod> getMethodsForCountry(Country country, 
								List<PaymentMethod> availableMethods) {
		List<PaymentMethod> methodsForCountry = Lists.newArrayList();
		for (PaymentMethod method : availableMethods) {
			if (method.isEligibleForCountry(country.getCode())) {
				methodsForCountry.add(method);
			}
		}
		return methodsForCountry;
	}
}
----

Well, yes, it seems that we are using the same code to create both sides of the assertion - actual and expected. This is plainly wrong! This way we can't really test whether this method works properly or not. We only know that it is idempotent. What we should do instead is to prepare the list of expected methods by hand, like this:

[source,java]
----
@Test
public void shouldGetMethodsForPoland() {
	//given
	List<PaymentMethod> methodsAvailableInPoland = Arrays.asList(new PaymentMethod[] {
		PaymentMethod.MASTERCARD,
		PaymentMethod.VISA,
		...
		// and all other methods available in Poland
	}

	//when
	List<PaymentMethod> methodsForCountry = PaymentMethod
		.getMethodsForCountry(new CountryBuilder().withCode("Pl").build(), all);

	//then
	assertThat(methodsForCountry).isEqualTo(methodsAvailableInPoland);
}
----
Ah, better now! :) This test does not use the logic of +PaymentMethod+ enum anymore, but simply provides a list of expected results.

[[sec_happy_path]]
== Happy Path
[quote, Wikipedie]
____
Happy path testing is a well-defined test case using known input, which executes without exception and produces an expected output.
____

The issue of writing '"happy path"' tests is so common, that it is probably the most popular antipattern of all.

But what is a '"happy path"' testing anyway? For our purpose, it is enough to say that '"happy paths"' tests cover the simplest, even obvious, scenarios. It is like testing that our calculator can add +2+ and +2+, and that if you add user +John Doe+ to the database then you can found it there.

Let me stress one thing though. Such tests are not evil. There is nothing wrong with having them. On the contrary *there are essential*. Why? Because the scenarios they cover are the most important for your application. If your application does not handle such simple cases then it is useless. So the problem is not with writing such tests, but with the fact that they are often the only tests there are. This of course leads to the problems as soon as the real data comes in - suddenly it occurs that your calculator can't handle negative values, and that your database is not prepared to handle a surname longer than 20 characters or so. And your clients will notice it really soon.

=== FizzBuzz
[quote, FizzBuzz RosettaCode]
____
Write a program that prints the integers from 1 to 100. But for multiples of three print "Fizz" instead of the number and for the multiples of five print "Buzz". For numbers which are multiples of both three and five print "FizzBuzz".
____

Let us have a look at this implementation of the test class which claims to verify whether the +FizzBuzz+ class behaves according to the specification presented above{empty}pass:[]footnote:[The test implementation is copied from CodeReview discussion, see: http://codereview.stackexchange.com/questions/9749].

[source,java]
----
public class FizzBuzzTest {
	@Test
	public void testMultipleOfThreeAndFivePrintsFizzBuzz() {
		assertEquals("FizzBuzz", FizzBuzz.getResult(15));
	}

	@Test
	public void testMultipleOfThreeOnlyPrintsFizz() {
		assertEquals("Fizz", FizzBuzz.getResult(93));
	}

	@Test
	public void testMultipleOfFiveOnlyPrintsBuzz() {
		assertEquals("Buzz", FizzBuzz.getResult(10));
	}

	@Test
	public void testInputOfEightPrintsTheNumber() {
		assertEquals("8", FizzBuzz.getResult(8));
	}
}
----

Looks decent, doesn't it? Each requirement is covered by testing it with one piece of test data.

However I would still call it a "happy path" test. The number of test cases is not enough to deduce whether the +FizzBuzz+ class gives correct answers for all integers from 1 to 100. It might, but it might not. I could even come with very simple implementation which pass this test but does not really fulfill the FizzBuzz requirements.

I do not say we should test every integer from the given range (even thought that would not be hard as there are only 100 of them), but I would definitely write some more test cases. The nice thing is that I do not have to write more test methods. All I have to do is to use more data. The next listing presents how to do it with TestNG.

TIP: If you prefer JUnit I would recommend you to use the JUnitParams library to achieve a similiar effect.

[source,java]
----
@Test
public class FizzBuzzTest {
	
	@DataProvider
	public static Integer[][] multipleOf3And5() {
		return new Integer[][]{{15}, {30}, {75}};
	}

	@Test(dataProvider = "multipleOf3And5")
	public void testMultipleOfThreeAndFivePrintsFizzBuzz(int multipleOf3And5) {
		assertEquals("FizzBuzz", FizzBuzz.getResult(multipleOf3And5));
	}

	@DataProvider
	public static Integer[][] multipleOf3() {
		return new Integer[][]{{9}, {36}, {81}};
	}

	@Test(dataProvider = "multipleOf3")
	public void testMultipleOfThreeOnlyPrintsFizz(int multipleOf3) {
		assertEquals("Fizz", FizzBuzz.getResult(multipleOf3));
	}

	@DataProvider
	private static final Object[][] multipleOf5(){
		return new Object[][] {{10}, {40}, {100}};
	}

	@Test(dataProvider = "multipleOf5")
	public void testMultipleOfFiveOnlyPrintsBuzz(int multipleOf5) {
		assertEquals("Buzz", FizzBuzz.getResult(multipleOf5));
	}

	@DataProvider
	private static final Object[][] numbers(){
		return new Object[][] {{2}, {16}, {23}, {47}, {52}, {56}, {67}, {68}, {98}};
	}

	@Test(dataProvider = "numbers")
	public void testInputOfEightPrintsTheNumber(int expectedNumber) {
		assertEquals("" + expectedNumber, FizzBuzz.getResult(expectedNumber));
	}
}
---- 

TIP: Play BizzBuzz with your friends. See http://en.wikipedia.org/wiki/Bizz_buzz for game instruction. :)

== Naming is the King
[verse, Cyprian Kamil Norwid, Vade-mecum: In lieu of introduction]
____
To give the proper word - to thing!
____

This is interesting issue because we are usually very good at giving good names to methods and variables in production code. However when it comes to tests we drop the good habits and perform a bad job. I suspect this is because in tests it is quite normal to have few objects of them same type which results in simple naming schemas like +productA+, +productB+, +productC+ etc. Sometimes it is good enough, but sometimes it could be well improved.

=== A Rose by any Other Name... Not Really!
The first example presents a simple case of a test related to permission-checking module. The next listing shows a small fragment of this test - a data provider which feeds test methods with data.

[source,java]
----
@DataProvider
public static Object[][] userPermissions() {
 Â  Â return new Object[][]{
 Â  Â  Â  Â {"user_1", READ},
        {"user_2", READ},
Â Â  Â  Â  Â {"user_2", WRITE},
        {"user_3", READ},
Â Â  Â  Â  Â {"user_3", WRITE},
        {"user_3", DELETE}
Â  Â  };
}
----

As you can see it connects three users (+user_1+, +user_2+, +user_3+) with some permissions (+READ+, +WRITE+, +DELETE+). Fine, but why +user_1+ can only +READ+ while +user_3+ can also +WRITE+ and +DELETE+? This is not obvious and if some test fails you will learn someting like: '"+user_3+ was expected to have +DELETE+ permission"'. Then you start scratching your head wondering why actually +user_3+ should have such permission. Of course the answer is nowhere to be found. It was obvious few months ago when this test was created but now? Who knows who the heck is +user_3+?

And the cure? See below.

[source,java]
----
@DataProvider
public static Object[][] userPermissions() {
 Â  Â return new Object[][]{
 Â  Â  Â  Â {"guest", READ},
        {"logged", READ},
Â Â  Â  Â  Â {"logged", WRITE},
        {"admin", READ},
Â Â  Â  Â  Â {"admin", WRITE},
        {"admin", DELETE}
Â  Â  };
}
----

A guest can only read, logged users can also write, and admin has all permissions. Now the error message - e.g. '"+admin+ was expected to have +DELETE+ permission"' makes sense.

=== Object1, Object2, Object3
Now let us consider another example. This is a (tiny) part of a complex integration test which creates a bunch of objects (mainly of the +Domain+ class). It uses a lot of helper methods which are responsible for creation of objects and also for saving them into the database.
// TODO obfuscate

[source,java]
----
Domain domain1 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domain1, "PL", 1);
daoTestHelper.domainCountry30DayStatistics(domain1, "US", 2);
Domain domain2 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domain2, "PL", 4);
daoTestHelper.domainCountry30DayStatistics(domain2, "US", 8);

// ... and so on till domain5 or so
----

What I hate about this are the names of domain objects suffixed with numbers (+domain1+, +domain2+ etc.). They bring no information about the state (role, properties) of the objects. Here comes an updated version:

[source,java]
----
Domain domainWith1PlClick = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domainWith1PlClick, "PL", 1, 0);
daoTestHelper.domainCountry30DayStatistics(domainWith1PlClick, "US", 2, 1);
Domain domainWith4PlClicks = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domainWith4PlClicks, "PL", 4, 2);
daoTestHelper.domainCountry30DayStatistics(domainWith4PlClicks, "US", 8, 4);
----

Believe me, these names makes perfect sense for this particular scenario and for the problem domain. They allow to come with very readable custom assertions similar to this:

[source,java]
----
assertThat(result).hasResultsForDomain(domainWith4PlClicks, 4);
----

Surprisingly this simple refactorings of names has helped me to undercover an issue hidden within the test code. I admit I haven't seen it when the original names of variables (+domain1+, +domain2+ etc.) were used. Look at the longer snippet of the original code. It repeats the same pattern of first creating a domain and then creating some statistics for it. However there is one place in which this pattern breaks. Can you spot it?

[source,java]
----
Domain domain1 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domain1, "PL", 1);
daoTestHelper.domainCountry30DayStatistics(domain1, "US", 2);
Domain domain2 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domain2, "PL", 4);
daoTestHelper.domainCountry30DayStatistics(domain2, "US", 8);
Domain domain3 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.DELETED);
daoTestHelper.domainCountry30DayStatistics(domain3, "PL", 16);
daoTestHelper.domainCountry30DayStatistics(domain3, "CZ", 32);
Domain domain4 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.ACTIVE);
daoTestHelper.domainCountry30DayStatistics(domain3, "US", 64);
Domain domain5 = daoTestHelper.addDomainAndAssociateWithCampaign(campaign, 30l, CampaignDomainAssocState.DELETED);
----

Well, maybe you spotted it (congratulations!) but I hadn't when I worked with the code. Only when I started renaming variables I noticed that in one place +domain3+ is used where +domain4+ should had been used (take a look at the next to last line). It hasn't influenced the outcome of the test (because this line is responsible for adding data which should not be included in the final result), but still it illustrates very well what happens if all variables names differ only so slightly. It is very simple to mix things up.

.Conclusion
It is the same like with classes. At first you begin with useless names like +ClientDAOImpl+ but then you learn that you can have much more intention-revealing names. +HibernateClientDAO+, +InMemoryClientDAO+, +HighPerformanceClientDAO+ or whatever describes this particular implementation. There is always something to say about your class. I believe the same applies to the variables used in tests. I often start with +campaignA+ and +campaignB+ but then it occuress to me that these should be really +campaign+ and +campaignWithSameAdvertiser+ (while in other test method I have +campaign+ and +campaignWithDifferentAdvertiser+). Try it, it makes your test code so much more readable!

TIP: Do not su/pre-fix names of test variables with letters or numbers! Find intention revealing names for them.

Whenever you create some object for testing purposes there is some reason behind. You create it because it is different from other objects. It has different properties. Do not be shy about it. Say it loud. Say it, by giving this object a unique, recognizable name.

[[sec_intention_revealing]]
=== What True and False Stand For?
[quote, Pilat, John 18:38]
____
What is truth?
____

If we expect our tests to act as a documentation then we need to put some effort into their readability. Consider the following example:

[source,java]
----
server = new MockServer(responseMap, true,
		new URL(SERVER_ROOT).getPort(), false);
----

This single line of code is responsible for creation of the +server+ object of the +MockServer+ class. It is later used in test code.

Nice, but what the heck does +true+ and +false+ mean here? What kind of server is actually created?

I do not expect you to have JavaDocs for +MockServer+ (which sounds like a utility class create especially for testing purposes), which means you need to browse the source code to find out. This is not a major problem (but it may be - depending on the complexity of +MockServer+ class), however this is a nuisance. And it means that this test does not play the role of documentation very well. In order to understand the test case we need to browse another documents (i.e. source code). This is not a tragedy but this is not good either.

And what can we do about this? There are at least three options.

[float]
==== Constants
First, we could create some static variables with intention-revealing names, like this:

[source,java]
----
private static final boolean RESPONSE_IS_A_FILE = true;
private static final boolean NO_SSL = false;

server = new MockServer(responseMap, RESPONSE_IS_A_FILE,
		new URL(SERVER_ROOT).getPort(), NO_SSL);

----

Now there is no doubt what kind of server is created. It does not use SSL and responds with a file. Better, isn't it? And we haven't had to work very hard to achieve this effect.

[float]
==== Private Methods
Another option is to replace the +new+ keyword with some more expressive statement. For example, we could create a private method within the test code.

[source,java]
----
private MockServer noSslFileServer() throws MalformedURLException {
	return new MockServer(responseMap, true,
		new URL(SERVER_ROOT).getPort(), false);
}
----

Then we create the server like this:

[source,java]
----
MockServer server = noSslFileServer();
----

This is more readable than the original version, however this solution is not really scalable{empty}pass:[]footnote:[See <<sec_assertions_vs_private_methods>> for similar discussion regarding assertions.]. The number of such private methods will grow along with the complexity of the +MockServer+: the more parameters and options, the more methods are needed.

[float]
==== Builders
The third approach requires some more work. Yeah, you guessed it already - we could use test data builders{empty}pass:[]footnote:[http://nat.truemesh.com/archives/000714.html] idea and express very clearly what kind of server is required. For example like this:

[source,java]
----
server = new MockServerBuilder()
		.withResponse(responseMap)
		.withResponseType(FILE)
		.withUrl(SERVER_ROOT)
		.withoutSsl()
		.create();
----

Is this approach better than the previous ones? Not necessarily, as it definitely requires more work. However the fact that we control the API allows us to shape it according to our liking. Maybe in the domain that this +MockServer+ works, this is a perfect solution (this one implicitly sets the '"no-SSL"' option, and shortens type and url setting):

[source,java]
----
server = new MockServerBuilder()
		.createFileServer(SERVER_ROOT)
		.withResponse(responseMap)
		.create();
----

Probably the more complex and more frequently created the class in question is, the more we benefit from test data builders.
// TODO ref to test data builders chapter

[[sec_should]]
=== Should is Better than Test
Once upon a time, where His Majesty King JUnit the Third ruled the land of Java testing, we were all forced to prefix our test methods with +test+ word. Somehow this custom survived the death of the king{empty}pass:[]footnote:[Some people accuse his younger brother (JUnit the Fourth) of murdering him. Others blame barbaric tribes of TestNG. Java 5 acolytes mention the lack of annotations as the reason of his doom. The rest does not care at all. But all are happy that he is gone.]. Which is really troublesome as we will soon see.

// TODO in relation to "test behaviour not methods" <<sec_test_behaviour>>

Take a look at the following example (looks like Groovy judging by the lack of semicolons):

[source,java]
----
@Test
public void testOperation() {
	configureRequest("/validate")
	rc = new RequestContext(parser, request)
	assert rc.getConnector() == null
	assert rc.getOperation().equals("validate")
}
----

Now what is the purpose of this test? The name says it should '"test operation"' which is rather vague. What kind of operation? What behaviour is expected? And when this test fails, will it be clear then what functionality does not work in the system?

The thing is, that the documentational value of this test is zero, or even less. It rather brings confusion than clarifies anything.

As shown by this example the first problem with test method prefixed with +test+ is that they tend to test 'something'. And when they fail, all you know is that 'something' in your system does not work as expected. And then the investigation begins. And can take hours.

Take a look at the next example which uncovers another downside of +test+ naming pattern. As the name of this test method says it '"tests query"'. 

[source,java]
----
@Test
public void testQuery(){
	when(q.getResultList()).thenReturn(null);
	assertNull(dao.findByQuery(Transaction.class, q, false));
	assertNull(dao.findByQuery(Operator.class, q, false));
	assertNull(dao.findByQuery(null, null, false));

	List result = new LinkedList();
	when(q.getResultList()).thenReturn(result);
	assertEquals(dao.findByQuery(Transaction.class, q, false), result);
	assertEquals(dao.findByQuery(Operator.class, q, false), result);
	assertEquals(dao.findByQuery(null, null, false), null);

	when(q.getSingleResult()).thenReturn(null);
	assertEquals(dao.findByQuery(Transaction.class, q, true).size(), 0);
	assertEquals(dao.findByQuery(Operator.class, q, true).size(), 0);
	assertEquals(dao.findByQuery(null, null, true), null);

	when(q.getSingleResult()).thenReturn(t);
	assertSame(dao.findByQuery(Transaction.class, q, true).get(0), t);
	when(q.getSingleResult()).thenReturn(o);
	assertSame(dao.findByQuery(Operator.class, q, true).get(0), o);
	when(q.getSingleResult()).thenReturn(null);
	assertSame(dao.findByQuery(null, null, true), null);
}
----

This test:

* definitely breaks SRP (see <<sec_srp>>),
* uses some magical switches (who tells me what +true+ and +false+ stand for? - see <<sec_intention_revealing>>),
* uses cryptic variables name (+q+, +o+ and +t+)

but all in all, it is a valuable test. Believe me, I analyzed every part of it, and it all makes some sense. However, I hate the way it looks. It is too long and it verifies too many scenarios.

And here we come to the second problem which often occurs in +test+ prefixed test methods. Once you write something like +testQuery()+ it feels natural to put there every test related to query. That is how such monstrous methods are born. Bad thing, really bad.

I'm convinced that this would never have happened if only the developer had started with +should+ prefix. When you type +should...+ it makes you think about some specific scenarios. And you end up with +shouldReturnNullWhenDaoReturnsNull()+ or with +shouldReturnSingleValueReturnedByDao()+ and so on, but you won't end up with +shouldTestQuery()+ unless you are really trying to anger me. ;)

The test would be much better if splitted into few test methods, like this:

[source,java]
----
@Test
public void shouldReturnNullListWhenDaoReturnsNull {
	....
}

@Test
public void shouldReturnEmptyListWhenDaoReturnsIt {
	....
}

@Test
public void shouldReturnNullSingleResultWhenDaoReturnsNull {
	....
}

@Test
public void shouldReturnSingleResultReturnedByDao {
	....
}
----

TIP: Start with +should+. Think about scenario. Do not use +test+ prefix.

=== When Test Name Lies
[quote, S.E. Hinton, The Outsiders]
____
I lie to myself all the time. But I never believe me. 
____

I often find test methods with misleading names. Take this one for example.

[source,java]
----
public void shouldInsertNewValues() {
	//given
	//when
	reportRepository.updateReport(ReportColumn.CAMPAIGN, 
		ReportColumn.LANDER, reportMap(BigDecimal.TEN));
	reportRepository.updateReport(ReportColumn.CAMPAIGN, 
		ReportColumn.LANDER, reportMap(new BigDecimal("5")));

	//then
	assertThat(reportRepository.getCount(ReportColumn.CAMPAIGN,ReportColumn.LANDER))
		.isEqualTo(1);
}
----

Does it really verifies whether '"new values are inserted"'? I wouldn't say so. Frankly I'm not 100% sure what this test is all about, but it rather seems to me that it verifies whether the new value overrides older one. If so, it should be rather named +shouldOverrideOldReportWithNewValues+.

Not a big deal, huh? Well, maybe not a big deal, but why should your test lie to you? If one of the tests' purposes is to serve as documentation than it is a bad joke to have tests lying to you.

As long as this test is green everything is good. But after you do some huge changes in this area of the system{empty}pass:[]footnote:[Remember that the only constant thing in software development is change. :)] and the tests suddenly fails you will be in real trouble. Does the scenario covered by this test is still valid? Should it be removed? Should it be changed... but how? Good luck solving this! 

TIP: Make sure the names of test methods are describing well the scenarios they cover. Be careful especially when updating tests. Are they still valid after the changes you have just introduced?

=== Implementation Details Are Not So Important
Indeed, the implementation details are not so important that they should be promoted to the test method name. Have a look at this example:

[source,java]
----
@Test
public void shouldReturnFalseIfTransactionIsPending() {
	//given
	transaction.setState(PayoutTransactionState.PENDING);

	//when
	boolean paid = transaction.isPaid();

	//then
	assertThat(paid).isFalse();
}
----

The name of this test method does not lie this time, but it specifies unnecessary details. It should rather state the business scenario that is being tested. For example:

[source,java]
----
@Test
public void pendingTransactionShouldNotBeConsideredAsPaid() {

	...
}
----

TIP: When thinking about the test method leave the implementation details. What matters are the requirements.

== Ceremony
BDD is great for telling stories. The +given/when/then+ rhythm is a great thing. And many tests benefit from this pattern. However sometimes I find it hard to justify the presence of the whole BDD ceremony in some very simple tests. Like the one shown below.

[source,java]
----
@Test
public void shouldBuildEmailSender() {
	// given
	String senderName = "Chuck Norris";
	String senderEmail = "chuck@norris.com";

	// when
	String emailSender = EmailUtils.buildEmailSender(senderName, senderEmail);

	// then
	assertThat(emailSender).isEqualTo("Chuck Norris <chuck@norris.com>");
}
----

When I look at the content of +given+, +when+ and +then+ sections I feel like they were added only to honor the tradition of BDD. It is like adding desing patterns to your production code not because they are required, but because someone told you should do so. With all respect to BDD ideas why not stick with something much simpler? For example like this:

[source,java]
----
@Test
public void shouldBuildEmailSender() {
	String emailSender = EmailUtils.buildEmailSender("Chuck Norris", "chuck@norris.com");
	assertThat(emailSender).isEqualTo("Chuck Norris <chuck@norris.com>");
}
----

Or even like this:

[source,java]
----
@Test
public void shouldBuildEmailSender() {
	assertThat(EmailUtils.buildEmailSender("Chuck Norris","chuck@norris.com")
		.isEqualTo("Chuck Norris <chuck@norris.com>");
}
----

Similarly this test also looks like a ceremony-overkill to me:

[source,java]
----
@Test
public void shouldBeAdministrator() {
	//given
	User user = new Administrator();

	//when
	boolean administrator = user.isAdministrator();
	boolean advertiser = user.isAdvertiser();
	boolean domainer = user.isDomainer();

	//then
	assertThat(administrator).isTrue();
	assertThat(advertiser).isFalse();
	assertThat(domainer).isFalse();
}
----

I would suggest shorter version with the exactly same testing power.

[source,java]
----
@Test
public void shouldBeAdministrator() {
	User user = new Administrator();

	assertThat(user.isAdministrator()).isTrue();
	assertThat(user.isAdvertiser()).isFalse();
	assertThat(user.isDomainer()).isFalse();
}
----

TIP: KISS. Keep It Simple Stupid!

== Assertions
Assertions part is where the real testing happens. This is where you verify whether things worked out as expected. Apart from being crucial to make the test valid and valuable, assertions have also great impact on documentation value of your tests.

Let us see few examples of not-so perfect assertions.

=== Say No to Complex Assertions
In unit tests assertions are usually not a problem. Your tests are focused and test one thing so there is usually only one assertion and everything is clear. However it is much worse with integration and end-to-end tests in which the assertion part could be huge.

Let us have a look at an example of such situation. This test verifies whether a certain artifact (+WAR+ file) was copied to some remote server.

[source,java]
----
@Test
public void shouldPreDeployApplication() {
	// given
	Artifact artifact = mock(Artifact.class);
	when(artifact.getFileName()).thenReturn("war-artifact-2.0.war");
	ServerConfiguration config 
		= new ServerConfiguration(ADDRESS, USER, KEY_FILE, TOMCAT_PATH, TEMP_PATH);
	Tomcat tomcat = new Tomcat(HTTP_TOMCAT_URL, config);
	String destDir = new File(".").getCanonicalPath() + SLASH + "target" + SLASH;
	new File(destDir).mkdirs();

	// when
	tomcat.preDeploy(artifact, new FakeWar(WAR_FILE_LENGTH));

	//then
	JSch jsch = new JSch();
	jsch.addIdentity(KEY_FILE);
	Session session = jsch.getSession(USER, ADDRESS, 22);
	session.setConfig("StrictHostKeyChecking", "no");
	session.connect();
	Channel channel = session.openChannel("sftp");
	session.setServerAliveInterval(92000);
	channel.connect();
	ChannelSftp sftpChannel = (ChannelSftp) channel;

	sftpChannel.get(TEMP_PATH + SLASH + artifact.getFileName(), destDir);
	sftpChannel.exit();

	session.disconnect();

	File downloadedFile = new File(destDir, artifact.getFileName());

	assertThat(downloadedFile).exists().hasSize(WAR_FILE_LENGTH);
}
----

As you can see the 'then' part is pretty huge and rather unpleasant. It contains a lot of implementation details which clutter the view. It is not so simple to read the test and understand the scenario it verifies. +
An interesting observation is that the real assertion happens in the last line of the test method. The rest of "then" part is only preparing for this final line.

How to make it better? Many of us would extract assertion part as private method. Ok, this would be better, but as we see in a minute (see <<sec_assertions_vs_private_methods>>) it can lead to some problems as well, so let us do something different.

[source,java]
----
public void shouldPreDeployApplication() {
	//given
	Artifact artifact = mock(Artifact.class);
	when(artifact.getFileName()).thenReturn(ARTIFACT_FILE_NAME);
	ServerConfiguration config 
		= new ServerConfiguration(ADDRESS, USER, KEY_FILE, TOMCAT_PATH, TEMP_PATH);
	Tomcat tomcat = new Tomcat(HTTP_TOMCAT_URL, config);

	// when
	tomcat.preDeploy(artifact, new FakeWar(WAR_FILE_LENGTH));

	// then
	SSHServerAssert.assertThat(ARTIFACT_FILE_NAME)
		.existsOnServer(config).hasSize(WAR_FILE_LENGTH);
}
----

Better, isn't it? Now the test code speaks in terms of the requested functionality and not in terms of implementation. Good.

My advice is that when you see the assertion part of your test code growing, you should stop and write the assertion as you would like it to be. Then replace all the current asserting code with this one-liner and try to implement your custom assertion. It is easier and less work than you think (no matter if you use Hamcrest or FEST Fluent Assertions).

TIP: Just say it. Write the assertions as you would like it to be. Then implement it.

Let us see another example of an overly complicated assertions.

As you can see below an indexing variable +i+ is used to navigate through the resulting list. Assertions are rather cryptic. At least for me it is not obvious that the third element of this list should have twelve views.

[source,java]
----
@Test
public void shouldGetDomainsFromCampaignWithStatisticsAndWithDeleted() {
	//given
	... some complex set-up here

	//when
	List<DomainObject> result = someDao.getStatistics(campaign, true, 100, 0);

	//then
	int i = 0;
	assertThat(result.size()).isEqualTo(5);
	assertThat(result.get(i).getCampaignId()).isEqualTo(campaign.getId());
	assertThat(result.get(i++).getViews()).isEqualTo(16);
	assertThat(result.get(i++).getViews()).isEqualTo(12);
	assertThat(result.get(i++).getViews()).isEqualTo(3);
	assertThat(result.get(i++).getViews()).isEqualTo(0);
	assertThat(result.get(i++).getViews()).isEqualTo(0);
}
----

As usual when it comes to making assertions more readable we can use private methods (not really recommended - see <<sec_assertions_vs_private_methods>>) or write our custom assertions. Since in this case the test verifies some very important part of the system, I decided it was worthwile to implement custom assertion. The result is shown on the next listing.

[source,java]
----
@Test
public void shouldGetDomainsFromCampaignWithStatisticsAndWithDeleted() {
	//given
	... some complex set-up here

	//when
	List<DomainObject> result = someDao.getStatistics(campaign, WITH_EXCLUDED, 100, 0);

	//then
	assertThat(result).hasStatisticsForDomains(5).allStatisticsAreForCampaign(campaign.getId());
	assertThat(result).isSortedByViews();
	assertThat(result).hasResultsForDomain(domainWith3Views, 3);
	assertThat(result).hasResultsForDomain(domainWith12Views, 12);
	assertThat(result).hasResultsForDomain(deletedDomainWith16Views, 16);
	assertThat(result).hasResultsForDomain(domainWith0Views, 0);
	assertThat(result).hasResultsForDomain(deletedDomainWith0Views, 0);
}
----

TODO refer to test data builders - this is the other side of the same coin

TIP: Let your tests (and assertions) speak with domain language, not in implementation terms.

[[sec_assertions_vs_private_methods]]
=== Avoid Assertions using Private Methods
So you have a test scenario. It is a complex integration test which covers some important functionality. At the end of it you write some assertions to make sure that the data in the database are in expected state. It can look like this:

[source,java]
----
@Test
public void testChargeInRetryingState() throws Exception {
	// given
	TxDTO request = createTxDTO(RequestType.CHARGE);
	AndroidTransaction androidTransaction = ...
	Processor processor = ...
	... much more complex set-up code here

	// when
	final TxDTO txDTO = processor.processRequest(request);

	// then
	assertEquals(txDTO.getResultCode(), ResultCode.SUCCESS);
	final List<AndroidTransactionStep> steps
		= new ArrayList<AndroidTransactionStep>(androidTransaction.getTransactionSteps());
	final AndroidTransactionStep lastStep = steps.get(steps.size() - 1);
	assertEquals(lastStep.getTransactionState(), AndroidTransactionState.CHARGE_PENDING);
	assertEquals(lastStep.getMessage(), ClientMessage.SUCCESS);
	... some more assertions here
}
----

So far so good. Now you write other tests. You soon discover that the assertions are very similar to the ones you have already written (they only differ by expected states - for example some another test method expects +AndroidTransactionState.SUBMITTED+ instead of +AndroidTransactionState.CHARGE_PENDING+). '"Reuse is good"' you think and you do the most obvious thing: you create a private method (which takes expected states as parameter) and call it from both tests. As you write more test code the same method is being called from more test method. +
This seems right. There is no code duplication among test methods because all assertions are done by this separated private method.

And all is good and well at least for some time. You write more tests still reusing this one assertion method. But soon you encounter problems. The assertions in the method are not exactly what you need in some particular test cases. They are very close to what you want, but not exactly. '"Reuse is good"' you say and make your private method more generic so it can handle more test cases. The resulting assertion method is presented below:

[source,java]
----
private void assertState(TxDTO txDTO, AndroidTransaction androidTransaction,
	AndroidTransactionState expectedAndroidState,
	AndroidTransactionState expectedPreviousAndroidState,
	ExtendedState expectedState,
	String expectedClientStatus,
	ResultCode expectedRequestResultCode) {

	final List<AndroidTransactionStep> steps
		= new ArrayList<AndroidTransactionStep>(androidTransaction.getTransactionSteps());
	final boolean checkPreviousStep = expectedAndroidState != null;
	assertTrue(steps.size() >= (checkPreviousStep ? 3 : 2));

	if (checkPreviousStep) {
		AndroidTransactionStep lastStep = steps.get(steps.size() - 2);
		assertEquals(lastStep.getTransactionState(),
		expectedPreviousAndroidState);
	}

	final AndroidTransactionStep lastStep = steps.get(steps.size() - 1);
	assertEquals(lastStep.getTransactionState(), expectedAndroidState);
	assertEquals(lastStep.getMessage(), expectedClientStatus);

	assertEquals(txDTO.getResultCode(), expectedRequestResultCode);
	assertEquals(androidTransaction.getState(), expectedAndroidState);
	assertEquals(androidTransaction.getExtendedState(), expectedState);

	if (expectedClientStatus == null) {
		verifyZeroInteractions(client);
	}
}
----

Oh my, this has come too far... Now we have a monster-method which verifies every possible scenario! It takes 7 parameters and has some logic. This is unmaintainable. You can't read your tests now and understand what scenario is really tested (without doing some serious investigations).

And what is the right way to do it? I would suggest to write a custom assertion. This allows to write the test in the following way:

[source,java]
----
public void testChargeInRetryingState() throws Exception {
        // given
        TxDTO request = createTxDTO(RequestType.CHARGE);
        AndroidTransaction androidTransaction = ...
        Processor processor = ...
        ... much more complex set-up code here

        // when
        final TxDTO txDTO = processor.processRequest(request);

        // then
        assertEquals(txDTO.getResultCode(), ResultCode.SUCCESS);
        assertThat(androidTransaction)
		.hasState(AndroidTransactionState.CHARGED)
                .hasMessage(ClientMessage.SUCCESS)
                .hasPreviousState(AndroidTransactionState.CHARGE_PENDING)
                .hasExtendedState(null);
}
----

What is the difference with the previous test? I do not claim to be super-simple but that is because the business domain of the tested system was complicated! I think that this version makes it much easier to understand what is the expected outcome of this test. There is no logic involved (no +if+ statements in the assertions part) which leaves no doubts about what is being asserted.

TIP: Whenever your assertions are growing beyond your safety limit (2 lines? 3 lines? 5 lines? I do not know, it is *yours safety limit* not mine) then introduce custom assertions instead. In fact, it seems reasonable to come with custom assertions for the main objects from your domain (because you will probably have many tests which involve them - both on unit and integration level).

And how to come with good custom assertions method? My trick is simply to write it so I am happy while reading this. So, without actually having any custom assertion implemented I write a line like this in my test code:

[source,java]
----
assertThat(client).isVip().and().hasDiscount(0.2)
----

And then I implement it. Of course sometimes it happens that I need to deviate from the original plan and that the resulting fluent interface differs in details, but usually I'm able to come quite close to what I imagined.

In another test that I have seen many test methods like this one:

[source,java]
----
@Test
public void testCompile_32Bit_FakeSourceFile() {
	CompilerSupport _32BitCompilerSupport
		= CompilerSupportFactory.getDefault32BitCompilerSupport();
	testCompile_FakeSourceFile(_32BitCompilerSupport);
}
----

It is not easy to figure out what scenario is tested by this method. In fact this is almost impossible without looking into the +testCompile_FakeSourceFile()+ method. So let us have a look at it.

[source,java]
----
private void testCompile_FakeSourceFile(CompilerSupport compilerSupport) {
	String[] compiledFiles = compilerSupport.compile(new File[] { new File("fake") });
	assertThat(compiledFiles, is(emptyArray()));
}
----

Hm... clear? Not to me. I still can not tell you what is story behind +testCompile_32Bit_FakeSourceFile+. Is it because I know nothing about the domain of the problem? To some extente the answer is yes. However I suspect that even if I knew it very well I still would had to figure out the purpose of this method. It seems to me that some improvement is possible.

The trouble with this test is because the +testCompile_FakeSourceFile+ is doing two things at once: it executes the tested functionality of the SUT and also asserts on it.
What I would suggest is to get rid of this helper private method by inlining it.

[source,java]
----
@Test
public void testCompile_32Bit_FakeSourceFile() {
	CompilerSupport _32BitCompilerSupport
		= CompilerSupportFactory.getDefault32BitCompilerSupport();
	String[] compiledFiles = compilerSupport.compile(SINGLE_FAKE_FILE);
	assertThat(compiledFiles, is(emptyArray())));
}
----

Then I would consider renaming the test method and writing a custom assertion to better express the intention behind this test.

[source,java]
----
@Test
public void compiler32BitShouldNotBotherToCompileFakeSourceFile() {
	CompilerSupport _32BitCompilerSupport
		= CompilerSupportFactory.getDefault32BitCompilerSupport();
	String[] compiledFiles = compilerSupport.compile(SINGLE_FAKE_FILE);
	assertThat(compiledFiles).nothingWasCompiled();
}
----

Is it better? In my opinion yes. Now I can read the test method alone and understand it.

[float]
==== Cost of Custom Assertions
There is a question which could be asked by an inquisitive reader. Custom assertions contain some code, even some logic. How can I be sure that there is no mistake there?

Ok, I admit. I do not test my custom assertions. This comes from few facts.

First of all the logic of custom assertions is *very* limited (if any at all). Usually they boil down to fetching some properties of an object and comparing it with expected result. Writing custom assertions for your domain objects you will rarely find a need for a +for+ loop there or anything more complex. It often happens that the majority of code is devoted to the creation of custom error messages. +
This looks different for custom assertions which are more related to integration tests - like the one discussed in <<sec_asserting_too_much>>. In such case you can consider writing of tests for your assertions.

Secondly, custom assertions are often written after you have already written assertions in your tests. This is rather natural. At some point of writing your test you realize that the assertion part of it is getting too big and/or too complicated. Then you create your custom assertion class and copy there parts of your assertions. This usually happens when you verified your assertions working (by running tests). 

=== Assertions Should Be Merciless
Ending your test with +assert+ is not enough. The point is to have assertion(s) which really verify the scenario that is being tested. Which is not always the case as proved by this example.

[source,java]
----
@Test
public void shouldRemoveEmailsByState() {
	//given
	Email pending = createAndSaveEmail("pending","content pending","abc@def.com", Email.PENDING);
	Email failed = createAndSaveEmail("failed","content failed","abc@def.com", Email.FAILED);
	Email sent = createAndSaveEmail("sent","content sent","abc@def.com", Email.SENT);

	//when
	emailDAO.removeByState(Email.FAILED);

	//then
	assertThat(emailDAO.findAll()).excludes(failed);
}
----

This test first creates three email entities and stores them in database. Then it executes the +removeByState()+ method of the +emailDAO+ SUT. Next it verifies whether... well, yes, what does it really verify?

The assertion makes sure that the +failed+ email is not in the database anymore. However it does not prove that the +removeByState()+ works as expected. In particular, if it is flawed and removes all emails, then the test still passes.

My suggestion would be to protect ourselves against such issues by writing slightly more challenging. For example like this:

[source,java]
----
assertThat(emailDAO.findAll()).isNotEmpty().excludes(failed);
----

or even better like this:

[source,java]
----
assertThat(emailDAO.findAll()).includes(pending, sent).excludes(failed);
----

This way we verify exactly what was removed from database.

== Expected Objects
Each test should tell a story of what happens and what is expected. The story spans through the whole test and every part of the test takes part in its telling.

I find some tests which fail to tell the story when it comes to assertion. Have a look at the following test. Only a tiny part of it is presented so we can concentrate on the issue at hand.

[source,java]
----
@Test
public void shouldReturnModelWithCorrectValuesCalculated() {
	//given
	...

	//when
	DataModel result = ...;

	//then
	DataModel expectedResult = new DataModel<>(3.275, 1, 100);
	assertThat(result).isEqualTo(expectedResult); // value should be (1+5+50+75=131)/(10+10+10+10=40) = 3.275
}
----

The name of the test says that the SUT +shouldReturnModelWithCorrectValuesCalculated()+. The comment at the end of the last assertion line tells me exactly what was important for the creator of the test. There is some average value calculated, and it is essential that it is equal to 3.275. If so, then instead of comparing full objects, let us verify this one value:

[source,java]
----
	// then
	assertThat(result.getAverageValue()).isEqualTo(3.275);
----

After this change the test tells its story much better. The assertions part corresponds to the title of the test by specifying exact values which were expected to be calculated.
 
By changing the assertion as we did we also also cure another, not yet mentioned, weakness of the previous version of this test. When the test fails and the compared objects do not overwrite the +toString()+ method then all you get is a cryptic error message. Like this one:

----
org.junit.ComparisonFailure:
Expected :my.company.DataModel@e6037658
Actual   :my.company.DataModel@4af66537
----

Another drawback of such test is, that it can fail if compared objects differ with regard to some unimportant details.

Now you have few options:

* run the test again in debug mode to see what is the problem,
* add reasonable +toString()+ method to the +DataModel+ class,
* write custom assertions.

When verifying specified properties instead of objects you are sure to get a valuable error message which tells exactly which of them is different than expected.

TIP: Comparison of objects brings the scenario of the test to technical aspect. The story behind the test is gone, all we know that two objects should match at the end. I suggest to put few assertions (or even better to write custom one) instead of comparing objects.

== Creation of Objects
We haven't really discussed the part of the test which is responsible for objects creation.

=== Polluting Production Code
First of all, the weak organisation of this part of tests often influences the production code. Take for example the following part of the +User+ class:

[source,java]
----
public User() {
}

public User(String firstName, String lastName, String password, String email, 
		String activationCode, Date registered, UserState state, Address address) {
	this.firstName = firstName;
	this.lastName = lastName;
	... etc.
}

public User(String email, String firstName, String lastName, String password, 
		UserState userState, Address address) {
	this.email = email;
	this.firstName = firstName;
	... etc.
}

public User(String email, String firstName, String lastName, String password, 
		String timezone, UserState userState, Address address) {
	this.email = email;
	this.firstName = firstName;
	... etc.
}

public User(String email, String firstName, String lastName, Date registered, 
		String activationCode, Date activationDate, String password, 
		String timezone, BigDecimal accountBalance, UserState userState, 
		Address address, BigDecimal currentBalance) {
	this.email = email;
	this.firstName = firstName;
	... etc.
}
----

As you can see there are five different constructors there! All of them - with the exception of the parameterless one - were created for testing purposes. Different tests required object of the +User+ class to have different properties set and this is how all these constructors were created. Later on, the same constructors were also used in the code. +
This is not good. Objects creation code is now a mess of constructor calls with additional setters calls (because after some time it had occured that two more properties were also required). Also, the order of parameters is different: sometimes the first one is +email+, sometimes it is +firstName+. This is confusing. The 12-parameters constructor with many +String+ and +BigDecimal+ parameters is also confusing.

TIP: Do not add constructors to your domain classes only to make your test code simpler.

The problem with the code above is that no one stopped and criticly looked at the emerging constructors. If a proper code review had been performed, then this bad code would had been stopped at the very beginning with relatively low cost.

And the solution? Create a +UserBuilder+ class which takes care of construction of the +User+ objects. This way the production code would had only single parameterless constructor.

If you do not do that, you will end up with your tests filled with the objects construction looking like this:

[source,java]
----
AccountUpdateParameters updateParameters 
	= new AccountUpdateParameters(false, null, beforeUpdateAccount.isExternal(),
                false, null, false, null, false, null, false, null);
----

In case of builders you have a chance to create objects using more meaningful methods. Like this:

[source,java]
----
AccountUpdateParameters updateParameters = new AccountUpdateParameters().external().build();
----

=== Test Data Builders Simplify Test Code
TODO better than private methods because reusable 

////
http://code.google.com/p/fluent-builders-generator-eclipse-plugin/
http://www.jetbrains.com/idea/webhelp/replace-constructor-with-builder.html
////

TODO use builders instead of adding of constructor to your domain model classes

An utility class used by integration tests (which create a lot of objects then save them to database so they can be further updated, searched, retrieved etc.).

TODO example from DaoTestHelper - construction of objects with few BigDecimal parameters - show how to replace with constants and builders Problems: hard to understand.

=== It is so Easy to Make a Mistake
To finish, let us see yet another example which shows how use of multi-parameter constructors can bring confusion to your test code. Below the two beginnings of test methods from the same test class are presented:

[source,java]
----
@Test
public void shouldCreateUserAndFindHimById() {
	//given
	User user = new User("elvis2", "elvis@is.alive");
	...
}

@Test
public void shouldUpdateUser() {
	// given
	User user = new User("elvis@com.pl", "elvis3");
	...
}
----

Hm... what is going on here? What is the first parameter - email or name? Because you can not see into the production code I will tell you. It is the email. And the second parameter is (surprise, surprise!) a password! Yes, a password. Wasn't that clear to you? Nor to me. :) That is what happens when you use silly values for parameters and you use multi-parameters constructors instead of builders.

NOTE: I was really surprised to see a mistake in use of the two-parameters only constructore! I thought such mistakes happen if you have more than 5 parameters or so...

A better version would create user objects like this:

[source,java]
----
User user = new User(USER_EMAIL, USER_PASSWORD);
----

or like this (to demonstrate that *any* users would do):

[source,java]
----
User user = new UserBuilder().standardUser();
----

or like this (if only email is important):

[source,java]
----
User user = new UserBuilder().standardUser()
	.but().withEmail("elvis@presley.com");
----

or like this (if both parameters have some significance to the test case):

[source,java]
----
User user = new UserBuilder().standardUser()
	.but().withEmail("elvis@presley.com")
	.and().withPassword("sivle");
----

A lot of options to choose from. Depending on the context and your likings select the most suitable one.

TIP: Don't be satisfied with Test Data Builders implementation generated by IDEs! Shape them to your liking so you can write really readable test code.

=== Use Simpler Types
Let us see another example of object creation which could be improved. Consider the following test fragment:

----
TODO
----

This code creates objects of the +User+ class. This test code reflects the complexity of the business domain, which requires to use +BigDecimal+ objects. However, if you look at the values which are used, you will notice that integers would suffice. Which means, that we actually could you integers, if only the TODO methodName would allow as to do so. Since it is us who decide how this API looks like, there is no problem with update of required method. After this change, the test code can look like this:

----
TODO
----

Not a big deal, but if you have 5 such objects created within your test code (which is not so unusal for complex integration tests) then the difference might be significant.

Even though this example has used private methods for objects creation, the advice given here also applied to Test Data Builders. Similarly, we should equipe them with methods which allow us to use simple objects. For example, I have learned that adding methods which takes +String+ representation of dates (e.g. '"2013-05-23"') instead of +Date+ objects makes test code much more readable.

== Know Your Tool
TODO

* test which should be concurrent - not very likely to find a test for this

=== Expected Exceptions And Verification
// TODO NOTE: We should rather strive for SRP but sometimes it makes sense to test more things in one test.

Consider the following method from production code:

[source,java]
----
public void registerDomain(Domain domain) {
	try {
		dnsService.addDomainIfMissing(domain.getAddress());
	} catch (RuntimeException ex) {
		domainService.saveDomain(domain, domain.isRegisteredInDns(), 
			domain.getDnsFailures() + 1);
		throw ex;
	}
	domainService.saveDomain(domain.isRegisteredInDna(), domain.getDnsFailures());
}
----

A developer intended to verify whether even in case of exception the +saveDomain()+ method of the +DomainService+ class is called with appropriate parameters (i.e. with the increased number of DNS failures). Let us take a look at the test code:

[source,java]
----
@Test(expected = RuntimeException.class)
public void shouldSaveInformationOnFailureWhenExceptionOccurWhenAddingDomain() {
	//given
	doThrow(new RuntimeException()).when(pdnsService)
		.addDomainIfMissing(DOMAIN_ADDRESS);

	//when
	domainRegistrator.registerDomain(domain);

	//then
	verify(domainService)
		.saveRegisteredInDnsAndDnsFailures(domain, false, DNS_FAILURES + 1);
}
----

As you can see there are two verifications. First, the test verifies whether an exception is rethrown. This is done with the +expected+ attribute of the +@Test+ annotation. Second, the last line verifies that the expected method of the +domainService+ collaborator was called.

That is exactly what we wanted to have, right? Well, almost, because it does not work!

The problem is that the second verification never happens. Why? Because this line:

[source,java]
----
domainRegistrator.registerDomain(domain);
----

throws an exception which ends the execution of this test!

The fix is straightforward. We need to catch the exception within the test so that the last line is also executed. This can be done with a standard +try/catch+ statement, but we can do better than this using the catch-exception library:

[source,java]
----
@Test
public void shouldSaveInformationOnFailureWhenExceptionOccurWhenAddingDomain() {
	//given
	doThrow(new RuntimeException()).when(pdnsService)
		.addDomainIfMissing(DOMAIN_ADDRESS);

	//when
	catchException(domainRegistrator).registerDomain(domain);

	//then
	verify(domainService)
		.saveRegisteredInDnsAndDnsFailures(domain, false, DNS_FAILURES + 1);
	assertThat(caughtException()).isInstanceOf(RuntimeException.class);
}
----

As you can see we got rid of the +expected+ attribute from +@Test+ annotation. Instead we catch the exception using +catchException()+ method and then verify it using +caughtException()+ method. +
After this change the test is no longer interrupted when the exception is thrown and all verifications are performed.

TIP: Testing frameworks aren't very complex, however there are always some 'gotchas'. Make sure to read some documentation.

There is one more thing left to point out. I bet *the original test was written after the code*. If the developer had followed the TDD rules, he/she would had first run the test, see it fail and only then implement the feature. Working code-first you risk that you create useless tests.

TIP: Always see the failing test first.

=== Parametrized Test
TODO StepRoutineTest

=== Mockito any() vs. isA()
TODO make test code snippets bigger

NOTE: This example is a courtesy of Bartek Zdanowski (http://blog.bartekzdanowski.pl/). Thank you!

Let us consider the following production code:

[source,java]
----
public class AddOrganizationAction implements Action {}
public class AddPersonToOrganizationAction implements Action {}

public interface DispatchAsync {
	void execute(Action action, AsyncCallback callback);
}
----

In many cases we might be tempted to verify the execution of the +execute()+ method using the +any()+ matcher, like this:

[source,java]
----
verify(async).execute(any(AddOrganizationAction.class),
	any(AsyncCallback.class));
----

This looks right. However there is one issue with this code. Let us try to change the first argument from +AddOrganizationAction.class+ into +AddPersonToOrganizationAction.class+:

[source,java]
----
verify(async).execute(any(AddPersonToOrganizationAction.class),
	any(AsyncCallback.class));
----

To our surprise the test will still pass! Why is that? TODO finish

[source,java]
----
verify(async).execute(isA(AddOrganizationAction.class),
	any(AsyncCallback.class));
----

TIP: Search for +any()+ usages in your Mockito-powered tests and think about changing them to +isA()+.
TODO http://blog.bartekzdanowski.pl/2011/08/mockito-catch.html

=== Parametrized Tests
TODO some test which could be written better with data providers (or happy <<sec_happy_path>> path test because someone did not want to bother writing too many test methods)

=== Timeout
* test which should have timeout annotation

[[sec_thread_sleep]]
== Thread.sleep()
[verse, The New England Primer, 1697]
____
Now I lay me down to sleep,
I pray the Lord my soul to keep,
If I shall die before I wake,
I pray the Lord my soul to take. Amen.
____

TODO any example of such things?

* got selenium one - mention it can leverage what frameworks provide
* need something else to introduce awaitility

=== Await
TODO e2e recent test

=== ExecutorService
TODO algorithm.storeSuccess

[source,java]
----
public class SynchronousExecutorService extends AbstractExecutorService {
	private boolean shutdown;

	@Override
	public void shutdown() {
		shutdown = true;
	}

	@Override
	public List<Runnable> shutdownNow() {
		shutdown = true;
		return Collections.emptyList();
	}

	@Override
	public boolean isShutdown() {
		shutdown = true;
		return shutdown;
	}

	@Override
	public boolean isTerminated() {
		return shutdown;
	}

	@Override
	public boolean awaitTermination(final long timeout, final TimeUnit unit) {
		return true;
	}

	@Override
	public void execute(final Runnable command) {
		command.run();
	}
}
----

=== Timeout
Take a look at the following test. It verifies whether an object is removed from memcached repository after given time period passes.

[source,java]
----
public void shouldAddEntryAndRemoveAfterExpire() throws InterruptedException {
	//given
	memcachedRepository.setValue("key", 1, "value");
	memcachedRepository.setValue("key2", 10, "value2");
	Thread.sleep(1000);

	//when
	Object value = null;
	for (int i = 0; i < 10; i++) {
		value = memcachedRepository.getValue("key");
		if (value != null) {
			Thread.sleep(100);
		} else {
			break;
		}
	}

	//then
	assertThat(value).isNull();
	assertThat(memcachedRepository.getValue("key2")).isEqualTo("value2");
}
----

There are few things which make this test more complicated than it should be. First of all, it is unclear what is the meaning of numbers in the +given+ section. Let us refactor.

[source,java]
----
        //given
	memcachedRepository.setValue("key", ONE_SECOND_TTL, "value");
        memcachedRepository.setValue("key2", TEN_SECONDS_TTL, "value2");
        Thread.sleep(ONE_SECOND);
----

Now it is easier to understand the idea behind this test method. First it puts two elements into memcached with different TTL values{empty}pass:[]footnote:[TTL - Time To Live, which in this case refers to the time that given object should be kept in memcached.]. Then it waits one second (+Thread.sleep(ONE_SECOND)+) and a little bit more (the +for+ loop) so the first object is (automatically) removed from memcached (because its TTL was set to one second). The last part verifies that the first object was removed from memcached, while the other one is still there.

What bothers me still is this for loop. It seems complicated (as for a test code!). Let us try to do something about it.

[source,java]
----
@Test(timeout = 1500)
public void shouldAddEntryAndRemoveAfterExpire() throws InterruptedException {
	//given
	memcachedRepository.setValue("key", ONE_SECOND_TTL, "value");
	memcachedRepository.setValue("key2", TEN_SECONDS_TTL, "value2");
	Thread.sleep(ONE_SECOND);

	//when
	Object value = null;
	while (value == null) {
		value = memcachedRepository.getValue("key");
		Thread.sleep(100);
	}

	//then
	assertThat(value).isNull();
	assertThat(memcachedRepository.getValue("key2")).isEqualTo("value2");
}
----

Hm, the loop is simpler - that is for sure. 

TODO not really TODO Also the sleep inside the loop was removed. It wasn't really necessary.

TODO have doubts if this is a worthy example...

== Test Which Knows Too Much
Why tests are brittle? Because we put too many details into them. See the following example (this is a slightly shorthened test which from some mailing list discussion).

[source,java]
----
public void createSurvey() throws InterruptedException {		
	//CREATE SURVEY
	WebElement allproject = driver.findElement(By.xpath("//*[@id='projectnav']/ul/li[2]/a"));
	allproject.click();
	
	Thread.sleep(5000);
	
	WebElement myfolder = driver.findElement(By.linkText("John Doe"));
	myfolder.click();
		
	Thread.sleep(5000);
		
	WebElement myProject = driver.findElement(By.linkText("My project"));
	myProject.click();
		
	Thread.sleep(5000);
		
	WebElement createsurveylink = driver
		.findElement(By.xpath("//*[@id='bcontrol']/body/form[1]/table[2]/tbody/tr/td[2]/a[1]/img"));
	createsurveylink.click();
				
	Thread.sleep(5000);
		
	WebElement surveyname = driver
		.findElement(By.xpath("//*[@id='bcontrol']/body/form/table[4]/tbody/tr[2]/td[3]/input"));
	surveyname.sendKeys("Test Survey created on " + new Date());
		
	WebElement surveynameconfirm = driver
		.findElement(By.xpath("//*[@id='bcontrol']/body/form/table[1]/tbody/tr[2]/td[3]/a[2]/img"));
	surveynameconfirm.click();
		
	Thread.sleep(5000);
}
----

Before we get to the main point, let us discuss the idea of having +Thread.sleep()+ calls in your tests once again. We already did this in <<sec_thread_sleep>> but here situation is slightly different. The main reason of making the test so sloooooooow is because we are not sure when the browser will finish rendering the page so we can proceed the next click. True, we do not know that, so a defensive strategy is to set up some high values (5 seconds in this case) to stay on the safe side. It works, but makes your tests execution time horrible!

So, what can we do about it?  We can't make browser speed up, but we can wait actively, that is wait and repeatedly verify whether we can move do the next click. TODO about internal selenium mechanisms and about awaitility

TODO about Page objects

TODO about same pattern like builders and custom assertions - decoupling what changes from what is stable

So, putting these two together, the resulting test could look like this (it is hard to me to guess what was the business requirement of the test presented above, but I guess it was something like this):

[source,java]
----
public void shouldCreateSurvey() {
	Date date = new Date();

	ProjectsPage projectsPage = mainDashboard.goToProjectsPage();

	projectsPage.openProject("My project");

	SurverEditionPage surverEditionPage = projectsPage.createSurvey("Test Survery created on " + date);

	// there were no assertions in the original tests (which was rather weird...),
	// but I guess something like this would make sense
	String surveyName = surveyEditionPage.getEditedSurveyName();

	assertThat(surveyName).isEqualTo("Test Survey created on " + date);
}
----

What can we see here? Few things:

* most of the work is delegated to various +xyzPage+ objects which handle things like XPath access to various elements,
* no +Thread.sleep()+ - this is also handled internally by +xyzPage+ objects,
* this test would survive refactorings as long as the general flow of actions remains unchanged.

All this does not mean that the nasty low-level details have miracouleously vanished. No, as we already mentioned, they were moved to +xyzPage+ classes. For example, the +ProjectsPage+ class could look like the following:

[source,java]
----
TODO
----

[[sec_asserting_too_much]]
== Asserting Too Much
TODO comparison of objects with +equals+

Take a look at this test. Only the last lines of it are presented, but believe me - it was a really complex end-to-end test. It involved the SUT (the whole system) receive some requests and generate answers in form of CSV files.

[source,java]
----
@Test
public void invalidTxShouldBeCanceled() {
	... some complex test here

	// then
	String fileContent = 
		FileUtils.getContentOfFile("response.csv");
	assertTrue(fileContent.contains(
		"CANCEL,123,123cancel,billing_id_123_cancel,SUCCESS,"));
}
----

Look at the method name - +invalidTxShouldBeCanceled()+ (hint: 'Tx' stands for 'transaction') - and at the assertion made. Hm, do they match? Do you feel like the assertion really verifies if the invalid transaction was canceled? Well, it probably does, but it seem to test much more than this. In fact it verifies whether the received file conforms to some data pattern.

Another variant, which I would recommend, relies on - surprise, surprise! - custom annotations.

[source,java]
----
@Test
public void invalidTxShouldBeCanceled() {
	... some complex test here

	// then
	String fileContent = 
		FileUtils.getContentOfFile("response.csv");
	TxDTOAssert.assertThat(fileContent)
		.hasTransaction("123cancel").withResultCode(SUCCESS);
}
----

I like this version much more. It hides implementation details. Inside custom assertion code there is a logic which handles the file content (and extracts the status from single line of this CSV file) but it is hidden there, and does not clutter the test. It also reads much nicer: 'assert that response file contains entry about the transaction +123cancel+ which says it has finished successfuly (meaning, the cancelation of this transaction succeeded)'. 

Now when the CSV format changes, all you need to do is to fix the code encapsulated within the +TxDTOAssert+ class. In other case you would have to fix it in (many) tests which verify the content of the CSV file.

== Avoid Overspecified Tests
This section contains examples which illustrate another common issue with our tests. I see them often specify too many things which are not really related to the tested scenario. This reduces the readability of tests, and also influences their maintainability by increasing the number of things which force us to update the test code.

=== Mocking Is Not About Repeating Everything
The code below - copied from Mockito mailing list - is definitely breaking one of the rules of mocking: '"mock only types you own"'. But what it also does is that it is so very detailed that it describes every single bit of the production code (I say it without actually seeing the production code, but I bet this is the case!). This is bad. The test code is so tightly coupled to implementation that you can't introduce any changes there without breaking it.

And what does it really test? Well, everything and nothing at all at the same time. It verifies all the interactions between the SUT and its collaborators, but it even goes further: it stubs the SUT and then it verifies if it was stubbed! This is really useless unless your goal is to test Mockito's stubbing abilities (do not do that, thousands of people has already proved Mockito works fine!).

[source,java]
----
@Mock private DataSource dataSource;

@Mock private Mock connection;

@Mock private Mock statement;

@Mock private ResultSet resultSet;

@Test
public void test() throws Exception {
	MockitoAnnotations.initMocks(this);
	systemUnderTest = new OracleDAOImpl();
	systemUnderTest.setDBConnectionManager(connectionManager);
	Set<NACustomerDTO> set = new HashSet<NACustomerDTO>();
	when(connectionManager.getDataSource()).thenReturn(dataSource);
	when(dataSource.getConnection()).thenReturn(connection);
	when(connection.createStatement()).thenReturn(statement);
	when(statement.executeQuery(anyString())).thenReturn(resultSet);
	when(resultSet.next()).thenReturn(false);
	when(resultSet.getLong(1)).thenReturn(1L);
	when(resultSet.getString(2)).thenReturn("7178");
       
	doNothing().when(resultSet).close();
       
	stub(systemUnderTest.getNACustomers()).toReturn(set); <1>
	final Set<NACustomerDTO> result = systemUnderTest.getNACustomers();
       
 	verify(connectionManager).getDataSource();
 	verify(dataSource).getConnection();
 	verify(connection).createStatement();
	verify(statement).executeQuery(anyString());
	verify(resultSet).next();
	verify(resultSet).getLong(1);
	verify(resultSet).getString(2);
       
	assertNotNull(result); <2>
       
	verify(connectionManager).getDataSource().getConnection();
}
----
<1> Stubbing of the SUT.
<2> This line verifies whether the stubbing was successful.

TIP: Writing test for exisiting code is *NOT* about repeating it line by line!

Ok, that would be unfair to leave this test like this. I think we deserve at least few hints about testing your DAO layer.

The rule of thumb is, that your DAOs are something you should rather not unit test. Why? Because there is usually no logic there (DAO should be a thin wrapper over database stuff). Instead have integration tests which set up a real database. If your DAO is not vendor-specific, it can be any database which is convenient for testig - e.g. H2{empty}pass:[]footnote:[http://www.h2database.com]. Then verify that the entites inserted and fetched by your DAOs are what you expect them to be. Concentrate on the complicated stuff (provided that your DAO layer have such). Do not test simple CRUD functionality that your ORM is doing for you (if there is something wrong here - which is very unlikely - you will find out when running end-to-end tests).

TIP: Go search on http://stackoverflow.com/search?q=dao%20testing[Stack Overflow] for '"dao testing"' - you will find many good tips there.

=== Copy & Paste
Below a sample test which I wrote myself. It verifies whether some Maven-related utility class can recognize snapshot artifacts.

[source,java]
----
@DataProvider
public Object[][] snapshotArtifacts() {
	return new Object[][]{
		{"a", "b", "2.2-SNAPSHOT", Artifact.JAR },
		{"c", "d", "2.2.4.6-SNAPSHOT", Artifact.JAR},
		{"e", "f", "2-SNAPSHOT", Artifact.JAR}
	};
}

@Test(dataProvider = "snapshotArtifacts")
public void shouldRecognizeSnapshots(
		String groupId, String artifactId, 
		String version, Type type) {
	Artifact artifact
		= new Artifact(groupId, artifactId, version, type);
	assertThat(artifact.isSnapshot()).isTrue();
}
----

All is good and well but... If you look at the core of what the test tries to verify you will soon notice that only one parameter out of which are provided by +snapshotArtifacts()+ data provider is really relevant. Who cares about +groupId+, +artifactId+ and +type+ when only thing which matters is the version?

After the refactor the same test took the following form:

[source,java]
----
@DataProvider
public Object[][] snapshotVersions() {
	return new Object[][]{
		{"2.2-SNAPSHOT"},
		{"2.2.4.6-SNAPSHOT"},
		{"2-SNAPSHOT"}
	};
}

@Test(dataProvider = "snapshotVersions")
public void shouldRecognizeSnapshots(String version) {
	Artifact artifact
		= new Artifact(VALID_GROUP, VALID_ARTIFACT_ID, 
		version, VALID_TYPE);
	assertThat(artifact.isSnapshot()).isTrue();
}
----

As you can see it uses a lot of static values (e.g. +VALID_GROUP+) which role is to announce '"I'm a right value and I'm really not important for this test scenario"'.

NOTE: As I've confessed, this (bad) test was mine. After I discovered its weakness I asked myself how it happened that I wrote such a code. The answer was simple. It all started with "copy&paste" of data provider which was used in another test. For this another test the four parameters were required. However they were not appropriate for this one. Once again: when copying code make sure it really fits!

Another option would be to use a test builder pattern, like this:

[source,java]
----
TODO
----

== Tests Should Follow the Evolution of Code
Tests are meant to be a perfect documentation which is always up-to-date. Unfortunately this is not always so.

Below you can see one test that drew my attention during the code review. It tests the +Transaction+ class which holds information about the user involved within the transaction and the amount of transaction. Both presented test methods verify "negative" cases: the system should treat transactions with amounts equal or less than zero as invalid.

[source,java]
----
public class TransactionTest {

	@Test
	public void shouldRecognizeTransactionsWithZeroValueAsInvalid() {
		//given
		Transaction tx = new Transaction(BigDecimal.ZERO, new InternalUser());

		//when
		boolean actual = tx.validate();

		//then
		assertThat(actual).isFalse();
	}

	@Test
	public void shouldRecognizeTransactionWithNegativeValueAsInvalid() {
		//given
		Transaction tx = new Transaction(BigDecimal.ONE.negate(), new InternalUser());

		//when
		boolean actual = tx.validate();

		//then
		assertThat(actual).isFalse();
	}
}
----

This test was valid and reasonable some time ago, when the +validate()+ method looked like this:

[source,java]
----
public boolean validate() {
	return amount.compareTo(BigDecimal.ZERO) > 0;
}
----

However at the time when I reviewed the test the same method had the following form:

[source,java]
----
public boolean validate() {
	if (!user.isExternal()) {
		return false;
	}
	return amount.compareTo(BigDecimal.ZERO) > 0;
}
----

What it means is that both tests pass no matter whether the method properly verifies the +amount+ of transaction. The first check - +user.isExternal()+ - is what really makes both tests pass.

What happened here? Well, the code evolved, but the tests had not. Both test methods should had been modified by replacing instance of the +InternalUser+ class with the +ExternalUser+ class. Additionally another test should had been written to verify the behaviour of the +validate()+ method with valid amount and a non-external user.

NOTE: When your code evolves take care that your tests also evolve. The fact that they still pass is not enough to say that everything is fine!

And BTW. if you think about it some more... Shouldn't test evolve before the code rather than after it? It is not always applicable (especially in case of huge changes) but whenever possible, go for it!

== Waste of Time
There are some things which are not worth unit-testing. Really, there are. Getters/Setters and delegators are the best examples.

=== Things Too Simple to Break
Take for example this test (which, as all other tests in this book is real, however obfuscated).

[source,java]
----
@Test
public void shouldReturnImportantValue() {
	//given
	given(settings.getImportantValue()).willReturn(IMPORTANT_VALUE);

	//when
	BigDecimal importantValue = settingsFacade.getImportantValue();

	//then
	assertThat(importantValue).isEqualByComparingTo(IMPORTANT_VALUE);
}
----

The test is about two classes - the +SettingsFacade+ class which delegates calls to its collaborator of the +Settings+ class. The tested method looks like this:

[source,java]
----
public BigDecimal getImportantValue() {
	return settings.getImportantValue();
}
----

Hm.... What kind of error do we expect to catch by writing this kind of tests?

I often hear that the real reason for writing such tests is because of the future evolution of code. Once upon a time a simple getter or delegator method will be updated and then we will find out whether its current functionality has been broken. I do not share this view. First of all it goes against the YAGNI principle{empty}pass:[]footnote:[See http://en.wikipedia.org/wiki/You_ain%27t_gonna_need_it]. I can't give precise numbers but I would say that the vast majority (99%?) of such simple methods will not evolve. Which means that 99 times of 100 you wasted your time writing tests. Second, any mature developer understands that when introducing some logic into existing method she/he needs to review the tests and update them. Third, there is a chance that even if your unit tests won't notice the change, your higher level tests will. +
Fourth, the hope that the future change of such method will be caught by our test is... well, it is only a hope. The thing is that you can not predict the future evolution of the code. What if the code evolves like this:

[source,java]
----
public BigDecimal getImportantValue() {
	return (settings.getImportantValue() != null) ? settings.getImportantValue() : DEFAULT_VALUE;
}
----

Our old test will still pass, won't it? The thing is that it can prevent only *some* changes to the code.

NOTE: Test everything that can break. Do not waste your time testing what is 'too simple to break'.

[[sec_fix_the_code_first]]
=== Fix the Code Then Write Tests

example from CW - complicated factoryWhatever test

should fix the code, not try to somehow test it

TODO of course test-first is better

== Randomness
TODO ref Randomized Tests{empty}pass:[]footnote:[http://wiki.apidesign.org/wiki/RandomizedTests] by Jaroslav Tulach
TODO ref RandomizedTesting{empty}pass:[]footnote:[http://labs.carrotsearch.com/randomizedtesting.html] by Carrot Search Labs

== Write the Right Tests
In contrast to all other sections I have no code to present here. But I have a story to tell.

So I worked once upon a really good project. The codebase was above the average (comparing to other projects that I have seen or worked for), the architecture was right, the people were cool. Everything seemed to be in place. However as the complexity of our software grew we started to notice various issues. The charts presented on the client dashboard went bonkers when user changed a timezone. Our internal tool which simulated some of the users' behaviour was very fragile to the changes done in other parts of the system. It happened that during some big "refactorings" or merges we mysteriously "lost" some functionality. Users reported issues with exporting functionality which hanged when too many objects were involved. After registration notifications were not sent appropriately. And so on, and so on.

All of this was really irritating. We had tests, for God's sake! In fact, we had plenty of them. Our code was more OO than ever - every small class was testable and we really had unit tests covering them all! Still, we had so many issues with our project.

In the whole book we have put a lot of attention to writing our tests the right way. We pondered over things like the naming of variables, the lack of implementation details, the clarity of test code and so on. Each of them seems tiny but when you neglect many of them your tests will become a nightmare to maintain. I hope that you understand it very well now based on the examples given in this book (and also on your own experience).
If you spent your time just writing tests, you probably loose a lot of it. Some parts of your system need it more than others. Depending on the type of the application you write some type of tests (unit, integration, end-to-end, performance etc.) are probably more important than the rest. In the story I have just told you we put too much effort into unit testing but neglected end-to-end test. And we paid the price. We lost time writing useless tests for delegators methods{empty}pass:[]footnote:[A delegator method is one which does not do anything important on its own, but delegates the work to some collaborator.] and introducing hundreds of +Factory+ classes (so our code would be so very OO and beautifuly testable!) but we skipped the tests which would really tell us if all aspects of our system works for the users.

Don't just sit and write tests. First think which tests to write.

TIP: Write tests which make you confident that your system works.

== Things to Remember

* Single Responsibility Principle for tests
* Names are important!
* Test behaviour, not methods!
* Ask yourself "what is the purpose of this test?", "what is really important?"
* Think about readability (just say it)
* Test-last does not work
* Private methods for assertions do not work
* Tests work only if you treat them as first-class citizens
* Tests should speak in terms of business requirements and expected functionalities, but not in the language of implementation details!

<<<
[float]
== Help
Send me your tests!

<<<
[float]
== Practical Unit Testing with TestNG and Mockito
image::images/put_cover.jpg[width="200", float="right"]
If you feel like you want to know more about writing unit tests, mocking, assertions and all this stuff, then have a look at my previous book - http://practicalunittesting.com['"Practical Unit Testing with TestNG and Mockito"'] (2012). You can learn a lot from it!

Learn to write *high-quality unit tests* with the finest technologies of the Java world!

Please visit http://practicalunittesting.com[book's website] for more information.
